{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e5607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532be961",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('data_ready.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349236a",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e30112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= data['diameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16689ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['diameter'],axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd129aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "102f7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5efcc7",
   "metadata": {},
   "source": [
    "## Normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33bdccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b5209",
   "metadata": {},
   "source": [
    "## Applying different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fba14d",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a90305b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score LR 0.8520463022324927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr =LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred_lr=lr.predict(X_test)\n",
    "\n",
    "print(\"R2 score LR\",r2_score(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b7393",
   "metadata": {},
   "source": [
    "#### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c835501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score Lasso 0.4358462658902911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_r =Lasso()\n",
    "lasso_r.fit(X_train,y_train)\n",
    "y_pred_lasso_r= lasso_r.predict(X_test)\n",
    "\n",
    "print(\"R2 score Lasso\",r2_score(y_test,y_pred_lasso_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47b4ef",
   "metadata": {},
   "source": [
    "#### Elasticnet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a505dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score ElasticNet 0.5679467696502397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "ela_r = ElasticNet(l1_ratio=0.5)\n",
    "ela_r.fit(X_train,y_train)\n",
    "y_pred_ela_r= ela_r.predict(X_test)\n",
    "\n",
    "print(\"R2 score ElasticNet\",r2_score(y_test,y_pred_ela_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a630e",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76223151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.9602310726954227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg2 = DecisionTreeRegressor(random_state=42, min_samples_leaf=30,max_depth=12)\n",
    "tree_reg2.fit(X_train, y_train)\n",
    "\n",
    "y_pred=tree_reg2.predict(X_test)\n",
    "print(\"R2 score\",r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0142acf",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502c76a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score KNN 0.9392176892913386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_r = KNeighborsRegressor()\n",
    "knn_r.fit(X_train,y_train)\n",
    "y_pred_knn_r= knn_r.predict(X_test)\n",
    "\n",
    "print(\"R2 score KNN\",r2_score(y_test,y_pred_knn_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debf9342",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3fb2df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.9602310726954227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=12,min_samples_leaf=30, random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=tree_reg2.predict(X_test)\n",
    "print(\"R2 score\",r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b0b65",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5abb4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score GBR 0.9625949829546532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train,y_train)\n",
    "y_pred_gbr= gbr.predict(X_test)\n",
    "\n",
    "print(\"R2 score GBR\",r2_score(y_test,y_pred_gbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fff0168",
   "metadata": {},
   "source": [
    "#### XG Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e48c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score XGBR 0.9655773392755423\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "xgbr= XGBRegressor()\n",
    "xgbr.fit(X_train,y_train)\n",
    "y_pred_xgbr= xgbr.predict(X_test)\n",
    "\n",
    "print(\"R2 score XGBR\",r2_score(y_test,y_pred_xgbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5244c",
   "metadata": {},
   "source": [
    "## Applying Nural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc98139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryan Chaturvedi\\AppData\\Local\\Temp\\ipykernel_13888\\2646527517.py:8: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5f233",
   "metadata": {},
   "source": [
    "#### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2201cbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score MLP 0.9654911063949455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp=  MLPRegressor(random_state=1, max_iter=500)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp= mlp.predict(X_test)\n",
    "\n",
    "print(\"R2 score MLP\",r2_score(y_test,y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557a968",
   "metadata": {},
   "source": [
    "#### Searching for best NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ef3e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a5f6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model= Sequential()\n",
    "    counter=0\n",
    "    for i in range(hp.Int('num_layers',min_value=2,max_value=8)):\n",
    "        if counter==0:\n",
    "            \n",
    "            model.add(\n",
    "                Dense(\n",
    "                      hp.Int('units' + str(i),min_value=8,max_value=128,step=8),\n",
    "                      activation=hp.Choice('activation' + str(i),values=['relu','tanh','sigmoid']),\n",
    "                      input_dim=X_train.shape[1],\n",
    "                      kernel_regularizer=tensorflow.keras.regularizers.l1(0.001)\n",
    "            ))\n",
    "            #model.add(Dropout(hp.Choice('dropout' +str(i),values=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
    "            #model.add(BatchNormalization())\n",
    "        else:\n",
    "            \n",
    "            model.add(\n",
    "                Dense(\n",
    "                      hp.Int('units' + str(i),min_value=8,max_value=128,step=8),\n",
    "                      activation=hp.Choice('activation' + str(i),values=['relu','tanh','sigmoid']),\n",
    "                      kernel_regularizer=tensorflow.keras.regularizers.l1(0.001)\n",
    "            ))\n",
    "        counter=+1\n",
    "    \n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    \n",
    "    optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',[1e-2,1e-3,1e-4]))\n",
    "    #callbacks=callback\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mean_squared_error',\n",
    "        )\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5750dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_loss',\n",
    "    max_trials=5,\n",
    "    directory='project',\n",
    "    project_name='Kerastuner2',\n",
    "    overwrite=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68343f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 04s]\n",
      "val_loss: 7.261666774749756\n",
      "\n",
      "Best val_loss So Far: 3.4213948249816895\n",
      "Total elapsed time: 00h 00m 15s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train,y_train,epochs=5,batch_size=2500,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7769a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 4,\n",
       " 'units0': 32,\n",
       " 'activation0': 'relu',\n",
       " 'units1': 24,\n",
       " 'activation1': 'sigmoid',\n",
       " 'learning_rate': 0.001,\n",
       " 'units2': 8,\n",
       " 'activation2': 'tanh',\n",
       " 'units3': 16,\n",
       " 'activation3': 'relu',\n",
       " 'units4': 24,\n",
       " 'activation4': 'relu',\n",
       " 'units5': 48,\n",
       " 'activation5': 'tanh',\n",
       " 'units6': 40,\n",
       " 'activation6': 'relu',\n",
       " 'units7': 64,\n",
       " 'activation7': 'relu'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f4f6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1217a7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                384       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                792       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,537\n",
      "Trainable params: 1,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d104979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/2000\n",
      "33/33 [==============================] - 1s 9ms/step - loss: 2.9829 - val_loss: 2.5954\n",
      "Epoch 12/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 2.2717 - val_loss: 2.0216\n",
      "Epoch 13/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.8170 - val_loss: 1.6700\n",
      "Epoch 14/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.5249 - val_loss: 1.4217\n",
      "Epoch 15/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.3100 - val_loss: 1.2351\n",
      "Epoch 16/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.1431 - val_loss: 1.0850\n",
      "Epoch 17/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.0102 - val_loss: 0.9653\n",
      "Epoch 18/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.9045 - val_loss: 0.8703\n",
      "Epoch 19/2000\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8174 - val_loss: 0.7860\n",
      "Epoch 20/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.7398 - val_loss: 0.7188\n",
      "Epoch 21/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6817 - val_loss: 0.6680\n",
      "Epoch 22/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6399 - val_loss: 0.6317\n",
      "Epoch 23/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6110 - val_loss: 0.6060\n",
      "Epoch 24/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5896 - val_loss: 0.5894\n",
      "Epoch 25/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5735 - val_loss: 0.5720\n",
      "Epoch 26/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5613 - val_loss: 0.5663\n",
      "Epoch 27/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5524 - val_loss: 0.5527\n",
      "Epoch 28/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5430 - val_loss: 0.5454\n",
      "Epoch 29/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5358 - val_loss: 0.5372\n",
      "Epoch 30/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5300 - val_loss: 0.5328\n",
      "Epoch 31/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5246 - val_loss: 0.5276\n",
      "Epoch 32/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5197 - val_loss: 0.5237\n",
      "Epoch 33/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5150 - val_loss: 0.5207\n",
      "Epoch 34/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5129 - val_loss: 0.5154\n",
      "Epoch 35/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5069 - val_loss: 0.5102\n",
      "Epoch 36/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5032 - val_loss: 0.5062\n",
      "Epoch 37/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4992 - val_loss: 0.5023\n",
      "Epoch 38/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4953 - val_loss: 0.4991\n",
      "Epoch 39/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4925 - val_loss: 0.4971\n",
      "Epoch 40/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4893 - val_loss: 0.4940\n",
      "Epoch 41/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4865 - val_loss: 0.4899\n",
      "Epoch 42/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4837 - val_loss: 0.4884\n",
      "Epoch 43/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4802 - val_loss: 0.4836\n",
      "Epoch 44/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4782 - val_loss: 0.4821\n",
      "Epoch 45/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.4748 - val_loss: 0.4782\n",
      "Epoch 46/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4717 - val_loss: 0.4755\n",
      "Epoch 47/2000\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4696 - val_loss: 0.4732\n",
      "Epoch 48/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4672 - val_loss: 0.4712\n",
      "Epoch 49/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4642 - val_loss: 0.4696\n",
      "Epoch 50/2000\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4623 - val_loss: 0.4663\n",
      "Epoch 51/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4601 - val_loss: 0.4638\n",
      "Epoch 52/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4575 - val_loss: 0.4670\n",
      "Epoch 53/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4565 - val_loss: 0.4586\n",
      "Epoch 54/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4533 - val_loss: 0.4566\n",
      "Epoch 55/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4511 - val_loss: 0.4553\n",
      "Epoch 56/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4485 - val_loss: 0.4532\n",
      "Epoch 57/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4462 - val_loss: 0.4494\n",
      "Epoch 58/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4451 - val_loss: 0.4497\n",
      "Epoch 59/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4427 - val_loss: 0.4458\n",
      "Epoch 60/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4403 - val_loss: 0.4451\n",
      "Epoch 61/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4382 - val_loss: 0.4430\n",
      "Epoch 62/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4370 - val_loss: 0.4436\n",
      "Epoch 63/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4352 - val_loss: 0.4391\n",
      "Epoch 64/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4332 - val_loss: 0.4374\n",
      "Epoch 65/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4317 - val_loss: 0.4365\n",
      "Epoch 66/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4312 - val_loss: 0.4358\n",
      "Epoch 67/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4288 - val_loss: 0.4340\n",
      "Epoch 68/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4270 - val_loss: 0.4363\n",
      "Epoch 69/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4261 - val_loss: 0.4358\n",
      "Epoch 70/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4250 - val_loss: 0.4285\n",
      "Epoch 71/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4229 - val_loss: 0.4277\n",
      "Epoch 72/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4206 - val_loss: 0.4261\n",
      "Epoch 73/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4211 - val_loss: 0.4289\n",
      "Epoch 74/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4223 - val_loss: 0.4241\n",
      "Epoch 75/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.4177 - val_loss: 0.4219\n",
      "Epoch 76/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4155 - val_loss: 0.4236\n",
      "Epoch 77/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4153 - val_loss: 0.4242\n",
      "Epoch 78/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4135 - val_loss: 0.4188\n",
      "Epoch 79/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4117 - val_loss: 0.4175\n",
      "Epoch 80/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4104 - val_loss: 0.4168\n",
      "Epoch 81/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4099 - val_loss: 0.4184\n",
      "Epoch 82/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4096 - val_loss: 0.4139\n",
      "Epoch 83/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4071 - val_loss: 0.4133\n",
      "Epoch 84/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4076 - val_loss: 0.4112\n",
      "Epoch 85/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4061 - val_loss: 0.4102\n",
      "Epoch 86/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4047 - val_loss: 0.4109\n",
      "Epoch 87/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4038 - val_loss: 0.4159\n",
      "Epoch 88/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4029 - val_loss: 0.4077\n",
      "Epoch 89/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4022 - val_loss: 0.4100\n",
      "Epoch 90/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4010 - val_loss: 0.4084\n",
      "Epoch 91/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4007 - val_loss: 0.4052\n",
      "Epoch 92/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3986 - val_loss: 0.4042\n",
      "Epoch 93/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3981 - val_loss: 0.4038\n",
      "Epoch 94/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3980 - val_loss: 0.4019\n",
      "Epoch 95/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3968 - val_loss: 0.4033\n",
      "Epoch 96/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3956 - val_loss: 0.4024\n",
      "Epoch 97/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3949 - val_loss: 0.3999\n",
      "Epoch 98/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3936 - val_loss: 0.3997\n",
      "Epoch 99/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3930 - val_loss: 0.3989\n",
      "Epoch 100/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3922 - val_loss: 0.3992\n",
      "Epoch 101/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3920 - val_loss: 0.3980\n",
      "Epoch 102/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3903 - val_loss: 0.3966\n",
      "Epoch 103/2000\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3899 - val_loss: 0.3962\n",
      "Epoch 104/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3889 - val_loss: 0.3953\n",
      "Epoch 105/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3887 - val_loss: 0.3955\n",
      "Epoch 106/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3879 - val_loss: 0.3961\n",
      "Epoch 107/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3877 - val_loss: 0.3936\n",
      "Epoch 108/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3871 - val_loss: 0.3926\n",
      "Epoch 109/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3860 - val_loss: 0.3942\n",
      "Epoch 110/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3854 - val_loss: 0.3968\n",
      "Epoch 111/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3871 - val_loss: 0.3910\n",
      "Epoch 112/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3833 - val_loss: 0.3898\n",
      "Epoch 113/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3829 - val_loss: 0.3878\n",
      "Epoch 114/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3815 - val_loss: 0.3889\n",
      "Epoch 115/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3822 - val_loss: 0.3873\n",
      "Epoch 116/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3810 - val_loss: 0.3866\n",
      "Epoch 117/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3807 - val_loss: 0.3852\n",
      "Epoch 118/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3795 - val_loss: 0.3901\n",
      "Epoch 119/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3806 - val_loss: 0.3874\n",
      "Epoch 120/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3790 - val_loss: 0.3871\n",
      "Epoch 121/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3794 - val_loss: 0.3835\n",
      "Epoch 122/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3773 - val_loss: 0.3857\n",
      "Epoch 123/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3781 - val_loss: 0.3838\n",
      "Epoch 124/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3765 - val_loss: 0.3823\n",
      "Epoch 125/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3761 - val_loss: 0.3831\n",
      "Epoch 126/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3747 - val_loss: 0.3831\n",
      "Epoch 127/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3747 - val_loss: 0.3807\n",
      "Epoch 128/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3745 - val_loss: 0.3844\n",
      "Epoch 129/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3759 - val_loss: 0.3843\n",
      "Epoch 130/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3739 - val_loss: 0.3795\n",
      "Epoch 131/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3724 - val_loss: 0.3792\n",
      "Epoch 132/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3726 - val_loss: 0.3782\n",
      "Epoch 133/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3724 - val_loss: 0.3803\n",
      "Epoch 134/2000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.3715 - val_loss: 0.3781\n",
      "Epoch 135/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3705 - val_loss: 0.3779\n",
      "Epoch 136/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3714 - val_loss: 0.3761\n",
      "Epoch 137/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3708 - val_loss: 0.3801\n",
      "Epoch 138/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3699 - val_loss: 0.3766\n",
      "Epoch 139/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3692 - val_loss: 0.3750\n",
      "Epoch 140/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3683 - val_loss: 0.3747\n",
      "Epoch 141/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3683 - val_loss: 0.3744\n",
      "Epoch 142/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3683 - val_loss: 0.3728\n",
      "Epoch 143/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3672 - val_loss: 0.3755\n",
      "Epoch 144/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3672 - val_loss: 0.3739\n",
      "Epoch 145/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3676 - val_loss: 0.3731\n",
      "Epoch 146/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3666 - val_loss: 0.3724\n",
      "Epoch 147/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3656 - val_loss: 0.3716\n",
      "Epoch 148/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3652 - val_loss: 0.3762\n",
      "Epoch 149/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3658 - val_loss: 0.3725\n",
      "Epoch 150/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3648 - val_loss: 0.3705\n",
      "Epoch 151/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3642 - val_loss: 0.3698\n",
      "Epoch 152/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3642 - val_loss: 0.3702\n",
      "Epoch 153/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3641 - val_loss: 0.3709\n",
      "Epoch 154/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3632 - val_loss: 0.3684\n",
      "Epoch 155/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3633 - val_loss: 0.3775\n",
      "Epoch 156/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3646 - val_loss: 0.3691\n",
      "Epoch 157/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3628 - val_loss: 0.3690\n",
      "Epoch 158/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3624 - val_loss: 0.3668\n",
      "Epoch 159/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3622 - val_loss: 0.3665\n",
      "Epoch 160/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3616 - val_loss: 0.3685\n",
      "Epoch 161/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3601 - val_loss: 0.3677\n",
      "Epoch 162/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3614 - val_loss: 0.3686\n",
      "Epoch 163/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3603 - val_loss: 0.3657\n",
      "Epoch 164/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3591 - val_loss: 0.3644\n",
      "Epoch 165/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3589 - val_loss: 0.3675\n",
      "Epoch 166/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3603 - val_loss: 0.3632\n",
      "Epoch 167/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3586 - val_loss: 0.3637\n",
      "Epoch 168/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3587 - val_loss: 0.3640\n",
      "Epoch 169/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3585 - val_loss: 0.3655\n",
      "Epoch 170/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3582 - val_loss: 0.3653\n",
      "Epoch 171/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3576 - val_loss: 0.3717\n",
      "Epoch 172/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3588 - val_loss: 0.3620\n",
      "Epoch 173/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3565 - val_loss: 0.3621\n",
      "Epoch 174/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3592 - val_loss: 0.3665\n",
      "Epoch 175/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3574 - val_loss: 0.3626\n",
      "Epoch 176/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3583 - val_loss: 0.3600\n",
      "Epoch 177/2000\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3566 - val_loss: 0.3637\n",
      "Epoch 178/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3582 - val_loss: 0.3602\n",
      "Epoch 179/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3558 - val_loss: 0.3702\n",
      "Epoch 180/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3553 - val_loss: 0.3598\n",
      "Epoch 181/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3549 - val_loss: 0.3589\n",
      "Epoch 182/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3539 - val_loss: 0.3597\n",
      "Epoch 183/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3541 - val_loss: 0.3584\n",
      "Epoch 184/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3532 - val_loss: 0.3590\n",
      "Epoch 185/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3548 - val_loss: 0.3655\n",
      "Epoch 186/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3574 - val_loss: 0.3618\n",
      "Epoch 187/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3549 - val_loss: 0.3596\n",
      "Epoch 188/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3525 - val_loss: 0.3661\n",
      "Epoch 189/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3533 - val_loss: 0.3575\n",
      "Epoch 190/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3519 - val_loss: 0.3608\n",
      "Epoch 191/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3523 - val_loss: 0.3595\n",
      "Epoch 192/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3527 - val_loss: 0.3569\n",
      "Epoch 193/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3523 - val_loss: 0.3575\n",
      "Epoch 194/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3522 - val_loss: 0.3575\n",
      "Epoch 195/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3502 - val_loss: 0.3576\n",
      "Epoch 196/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3505 - val_loss: 0.3562\n",
      "Epoch 197/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3500 - val_loss: 0.3578\n",
      "Epoch 198/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3507 - val_loss: 0.3578\n",
      "Epoch 199/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3497 - val_loss: 0.3555\n",
      "Epoch 200/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3492 - val_loss: 0.3552\n",
      "Epoch 201/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3488 - val_loss: 0.3653\n",
      "Epoch 202/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3516 - val_loss: 0.3542\n",
      "Epoch 203/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3483 - val_loss: 0.3541\n",
      "Epoch 204/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3480 - val_loss: 0.3537\n",
      "Epoch 205/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3480 - val_loss: 0.3524\n",
      "Epoch 206/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3477 - val_loss: 0.3568\n",
      "Epoch 207/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3487 - val_loss: 0.3552\n",
      "Epoch 208/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3475 - val_loss: 0.3529\n",
      "Epoch 209/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3480 - val_loss: 0.3533\n",
      "Epoch 210/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3466 - val_loss: 0.3524\n",
      "Epoch 211/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3461 - val_loss: 0.3539\n",
      "Epoch 212/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3466 - val_loss: 0.3516\n",
      "Epoch 213/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3465 - val_loss: 0.3554\n",
      "Epoch 214/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3464 - val_loss: 0.3517\n",
      "Epoch 215/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3456 - val_loss: 0.3531\n",
      "Epoch 216/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3475 - val_loss: 0.3539\n",
      "Epoch 217/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3446 - val_loss: 0.3545\n",
      "Epoch 218/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3450 - val_loss: 0.3497\n",
      "Epoch 219/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3440 - val_loss: 0.3507\n",
      "Epoch 220/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3441 - val_loss: 0.3507\n",
      "Epoch 221/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3447 - val_loss: 0.3491\n",
      "Epoch 222/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3438 - val_loss: 0.3499\n",
      "Epoch 223/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3434 - val_loss: 0.3496\n",
      "Epoch 224/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3429 - val_loss: 0.3491\n",
      "Epoch 225/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3430 - val_loss: 0.3489\n",
      "Epoch 226/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3435 - val_loss: 0.3524\n",
      "Epoch 227/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3436 - val_loss: 0.3511\n",
      "Epoch 228/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3429 - val_loss: 0.3500\n",
      "Epoch 229/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3418 - val_loss: 0.3478\n",
      "Epoch 230/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3416 - val_loss: 0.3504\n",
      "Epoch 231/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3446 - val_loss: 0.3556\n",
      "Epoch 232/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3424 - val_loss: 0.3492\n",
      "Epoch 233/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3411 - val_loss: 0.3459\n",
      "Epoch 234/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3407 - val_loss: 0.3516\n",
      "Epoch 235/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3417 - val_loss: 0.3460\n",
      "Epoch 236/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3402 - val_loss: 0.3484\n",
      "Epoch 237/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3415 - val_loss: 0.3471\n",
      "Epoch 238/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3405 - val_loss: 0.3481\n",
      "Epoch 239/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3405 - val_loss: 0.3452\n",
      "Epoch 240/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3392 - val_loss: 0.3474\n",
      "Epoch 241/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3397 - val_loss: 0.3453\n",
      "Epoch 242/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3389 - val_loss: 0.3453\n",
      "Epoch 243/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3387 - val_loss: 0.3453\n",
      "Epoch 244/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3387 - val_loss: 0.3447\n",
      "Epoch 245/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3385 - val_loss: 0.3439\n",
      "Epoch 246/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3397 - val_loss: 0.3439\n",
      "Epoch 247/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3377 - val_loss: 0.3441\n",
      "Epoch 248/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3376 - val_loss: 0.3434\n",
      "Epoch 249/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3371 - val_loss: 0.3444\n",
      "Epoch 250/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3376 - val_loss: 0.3430\n",
      "Epoch 251/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3380 - val_loss: 0.3426\n",
      "Epoch 252/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3375 - val_loss: 0.3433\n",
      "Epoch 253/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3367 - val_loss: 0.3436\n",
      "Epoch 254/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3369 - val_loss: 0.3417\n",
      "Epoch 255/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3365 - val_loss: 0.3555\n",
      "Epoch 256/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3389 - val_loss: 0.3410\n",
      "Epoch 257/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3357 - val_loss: 0.3433\n",
      "Epoch 258/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3356 - val_loss: 0.3510\n",
      "Epoch 259/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3369 - val_loss: 0.3437\n",
      "Epoch 260/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3358 - val_loss: 0.3409\n",
      "Epoch 261/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3351 - val_loss: 0.3420\n",
      "Epoch 262/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3352 - val_loss: 0.3430\n",
      "Epoch 263/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3347 - val_loss: 0.3403\n",
      "Epoch 264/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3343 - val_loss: 0.3399\n",
      "Epoch 265/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3341 - val_loss: 0.3403\n",
      "Epoch 266/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3341 - val_loss: 0.3432\n",
      "Epoch 267/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3342 - val_loss: 0.3419\n",
      "Epoch 268/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3343 - val_loss: 0.3410\n",
      "Epoch 269/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3336 - val_loss: 0.3387\n",
      "Epoch 270/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3343 - val_loss: 0.3397\n",
      "Epoch 271/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3333 - val_loss: 0.3478\n",
      "Epoch 272/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3349 - val_loss: 0.3418\n",
      "Epoch 273/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3348 - val_loss: 0.3378\n",
      "Epoch 274/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3328 - val_loss: 0.3409\n",
      "Epoch 275/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3334 - val_loss: 0.3420\n",
      "Epoch 276/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3337 - val_loss: 0.3378\n",
      "Epoch 277/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3322 - val_loss: 0.3387\n",
      "Epoch 278/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3321 - val_loss: 0.3400\n",
      "Epoch 279/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3321 - val_loss: 0.3428\n",
      "Epoch 280/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3312 - val_loss: 0.3411\n",
      "Epoch 281/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3337 - val_loss: 0.3382\n",
      "Epoch 282/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3316 - val_loss: 0.3378\n",
      "Epoch 283/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3319 - val_loss: 0.3363\n",
      "Epoch 284/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3310 - val_loss: 0.3378\n",
      "Epoch 285/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3309 - val_loss: 0.3368\n",
      "Epoch 286/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3307 - val_loss: 0.3372\n",
      "Epoch 287/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3310 - val_loss: 0.3371\n",
      "Epoch 288/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3301 - val_loss: 0.3351\n",
      "Epoch 289/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3303 - val_loss: 0.3362\n",
      "Epoch 290/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3300 - val_loss: 0.3349\n",
      "Epoch 291/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3296 - val_loss: 0.3389\n",
      "Epoch 292/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3304 - val_loss: 0.3347\n",
      "Epoch 293/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3295 - val_loss: 0.3374\n",
      "Epoch 294/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3310 - val_loss: 0.3340\n",
      "Epoch 295/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3288 - val_loss: 0.3349\n",
      "Epoch 296/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3299 - val_loss: 0.3338\n",
      "Epoch 297/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3293 - val_loss: 0.3350\n",
      "Epoch 298/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3286 - val_loss: 0.3355\n",
      "Epoch 299/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3287 - val_loss: 0.3356\n",
      "Epoch 300/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3296 - val_loss: 0.3332\n",
      "Epoch 301/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3292 - val_loss: 0.3333\n",
      "Epoch 302/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3288 - val_loss: 0.3359\n",
      "Epoch 303/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3289 - val_loss: 0.3351\n",
      "Epoch 304/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3298 - val_loss: 0.3356\n",
      "Epoch 305/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3281 - val_loss: 0.3323\n",
      "Epoch 306/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3288 - val_loss: 0.3345\n",
      "Epoch 307/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3277 - val_loss: 0.3335\n",
      "Epoch 308/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3275 - val_loss: 0.3324\n",
      "Epoch 309/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3274 - val_loss: 0.3335\n",
      "Epoch 310/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3274 - val_loss: 0.3322\n",
      "Epoch 311/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3278 - val_loss: 0.3315\n",
      "Epoch 312/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3288 - val_loss: 0.3337\n",
      "Epoch 313/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3278 - val_loss: 0.3311\n",
      "Epoch 314/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3280 - val_loss: 0.3345\n",
      "Epoch 315/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3276 - val_loss: 0.3324\n",
      "Epoch 316/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3280 - val_loss: 0.3335\n",
      "Epoch 317/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3256 - val_loss: 0.3313\n",
      "Epoch 318/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3274 - val_loss: 0.3348\n",
      "Epoch 319/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3260 - val_loss: 0.3309\n",
      "Epoch 320/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3266 - val_loss: 0.3377\n",
      "Epoch 321/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3293 - val_loss: 0.3325\n",
      "Epoch 322/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3258 - val_loss: 0.3350\n",
      "Epoch 323/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3270 - val_loss: 0.3319\n",
      "Epoch 324/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3254 - val_loss: 0.3305\n",
      "Epoch 325/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3256 - val_loss: 0.3369\n",
      "Epoch 326/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3273 - val_loss: 0.3334\n",
      "Epoch 327/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3262 - val_loss: 0.3296\n",
      "Epoch 328/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3252 - val_loss: 0.3311\n",
      "Epoch 329/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3256 - val_loss: 0.3317\n",
      "Epoch 330/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3268 - val_loss: 0.3299\n",
      "Epoch 331/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3240 - val_loss: 0.3293\n",
      "Epoch 332/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3241 - val_loss: 0.3298\n",
      "Epoch 333/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3240 - val_loss: 0.3295\n",
      "Epoch 334/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3261 - val_loss: 0.3349\n",
      "Epoch 335/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3242 - val_loss: 0.3293\n",
      "Epoch 336/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3240 - val_loss: 0.3304\n",
      "Epoch 337/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3238 - val_loss: 0.3282\n",
      "Epoch 338/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3239 - val_loss: 0.3315\n",
      "Epoch 339/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3258 - val_loss: 0.3293\n",
      "Epoch 340/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3236 - val_loss: 0.3287\n",
      "Epoch 341/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3235 - val_loss: 0.3289\n",
      "Epoch 342/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3245 - val_loss: 0.3340\n",
      "Epoch 343/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3233 - val_loss: 0.3285\n",
      "Epoch 344/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3234 - val_loss: 0.3273\n",
      "Epoch 345/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3236 - val_loss: 0.3275\n",
      "Epoch 346/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3229 - val_loss: 0.3324\n",
      "Epoch 347/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3242 - val_loss: 0.3304\n",
      "Epoch 348/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3236 - val_loss: 0.3327\n",
      "Epoch 349/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3230 - val_loss: 0.3308\n",
      "Epoch 350/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3228 - val_loss: 0.3275\n",
      "Epoch 351/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3223 - val_loss: 0.3298\n",
      "Epoch 352/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3230 - val_loss: 0.3347\n",
      "Epoch 353/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3266 - val_loss: 0.3289\n",
      "Epoch 354/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3228 - val_loss: 0.3311\n",
      "Epoch 355/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3235 - val_loss: 0.3270\n",
      "Epoch 356/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3238 - val_loss: 0.3302\n",
      "Epoch 357/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3214 - val_loss: 0.3265\n",
      "Epoch 358/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3216 - val_loss: 0.3275\n",
      "Epoch 359/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3230 - val_loss: 0.3288\n",
      "Epoch 360/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3230 - val_loss: 0.3361\n",
      "Epoch 361/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3220 - val_loss: 0.3272\n",
      "Epoch 362/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3224 - val_loss: 0.3337\n",
      "Epoch 363/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3228 - val_loss: 0.3268\n",
      "Epoch 364/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3208 - val_loss: 0.3276\n",
      "Epoch 365/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3222 - val_loss: 0.3263\n",
      "Epoch 366/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3208 - val_loss: 0.3273\n",
      "Epoch 367/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3203 - val_loss: 0.3298\n",
      "Epoch 368/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3220 - val_loss: 0.3258\n",
      "Epoch 369/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3225 - val_loss: 0.3281\n",
      "Epoch 370/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3213 - val_loss: 0.3257\n",
      "Epoch 371/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3207 - val_loss: 0.3256\n",
      "Epoch 372/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3204 - val_loss: 0.3290\n",
      "Epoch 373/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3203 - val_loss: 0.3312\n",
      "Epoch 374/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3217 - val_loss: 0.3251\n",
      "Epoch 375/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3216 - val_loss: 0.3264\n",
      "Epoch 376/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3198 - val_loss: 0.3248\n",
      "Epoch 377/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3218 - val_loss: 0.3244\n",
      "Epoch 378/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3202 - val_loss: 0.3257\n",
      "Epoch 379/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3200 - val_loss: 0.3261\n",
      "Epoch 380/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3197 - val_loss: 0.3245\n",
      "Epoch 381/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3193 - val_loss: 0.3245\n",
      "Epoch 382/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3195 - val_loss: 0.3244\n",
      "Epoch 383/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3195 - val_loss: 0.3284\n",
      "Epoch 384/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3212 - val_loss: 0.3267\n",
      "Epoch 385/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3194 - val_loss: 0.3242\n",
      "Epoch 386/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3191 - val_loss: 0.3250\n",
      "Epoch 387/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3194 - val_loss: 0.3251\n",
      "Epoch 388/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3199 - val_loss: 0.3231\n",
      "Epoch 389/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3187 - val_loss: 0.3234\n",
      "Epoch 390/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3193 - val_loss: 0.3260\n",
      "Epoch 391/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3195 - val_loss: 0.3244\n",
      "Epoch 392/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3191 - val_loss: 0.3229\n",
      "Epoch 393/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3198 - val_loss: 0.3233\n",
      "Epoch 394/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3177 - val_loss: 0.3258\n",
      "Epoch 395/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3186 - val_loss: 0.3251\n",
      "Epoch 396/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3193 - val_loss: 0.3254\n",
      "Epoch 397/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3195 - val_loss: 0.3230\n",
      "Epoch 398/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3177 - val_loss: 0.3238\n",
      "Epoch 399/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3181 - val_loss: 0.3248\n",
      "Epoch 400/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3185 - val_loss: 0.3227\n",
      "Epoch 401/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3183 - val_loss: 0.3254\n",
      "Epoch 402/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3174 - val_loss: 0.3241\n",
      "Epoch 403/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3172 - val_loss: 0.3240\n",
      "Epoch 404/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3172 - val_loss: 0.3318\n",
      "Epoch 405/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3197 - val_loss: 0.3227\n",
      "Epoch 406/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3171 - val_loss: 0.3230\n",
      "Epoch 407/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3170 - val_loss: 0.3307\n",
      "Epoch 408/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3179 - val_loss: 0.3220\n",
      "Epoch 409/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3171 - val_loss: 0.3235\n",
      "Epoch 410/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3171 - val_loss: 0.3220\n",
      "Epoch 411/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3161 - val_loss: 0.3235\n",
      "Epoch 412/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3168 - val_loss: 0.3214\n",
      "Epoch 413/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3171 - val_loss: 0.3241\n",
      "Epoch 414/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3167 - val_loss: 0.3215\n",
      "Epoch 415/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3185 - val_loss: 0.3236\n",
      "Epoch 416/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3170 - val_loss: 0.3235\n",
      "Epoch 417/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3180 - val_loss: 0.3253\n",
      "Epoch 418/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3166 - val_loss: 0.3223\n",
      "Epoch 419/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3168 - val_loss: 0.3239\n",
      "Epoch 420/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3172 - val_loss: 0.3210\n",
      "Epoch 421/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3168 - val_loss: 0.3276\n",
      "Epoch 422/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3180 - val_loss: 0.3204\n",
      "Epoch 423/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3168 - val_loss: 0.3214\n",
      "Epoch 424/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3170 - val_loss: 0.3228\n",
      "Epoch 425/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3156 - val_loss: 0.3216\n",
      "Epoch 426/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3165 - val_loss: 0.3209\n",
      "Epoch 427/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3156 - val_loss: 0.3221\n",
      "Epoch 428/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3155 - val_loss: 0.3240\n",
      "Epoch 429/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3165 - val_loss: 0.3220\n",
      "Epoch 430/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3154 - val_loss: 0.3208\n",
      "Epoch 431/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3150 - val_loss: 0.3199\n",
      "Epoch 432/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3151 - val_loss: 0.3238\n",
      "Epoch 433/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3161 - val_loss: 0.3219\n",
      "Epoch 434/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3163 - val_loss: 0.3209\n",
      "Epoch 435/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3153 - val_loss: 0.3189\n",
      "Epoch 436/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3158 - val_loss: 0.3190\n",
      "Epoch 437/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3153 - val_loss: 0.3202\n",
      "Epoch 438/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3142 - val_loss: 0.3207\n",
      "Epoch 439/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3155 - val_loss: 0.3196\n",
      "Epoch 440/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3153 - val_loss: 0.3193\n",
      "Epoch 441/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3147 - val_loss: 0.3190\n",
      "Epoch 442/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3144 - val_loss: 0.3188\n",
      "Epoch 443/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3138 - val_loss: 0.3190\n",
      "Epoch 444/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3140 - val_loss: 0.3230\n",
      "Epoch 445/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3157 - val_loss: 0.3191\n",
      "Epoch 446/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3157 - val_loss: 0.3196\n",
      "Epoch 447/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3136 - val_loss: 0.3194\n",
      "Epoch 448/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3136 - val_loss: 0.3199\n",
      "Epoch 449/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3136 - val_loss: 0.3213\n",
      "Epoch 450/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3132 - val_loss: 0.3189\n",
      "Epoch 451/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3137 - val_loss: 0.3183\n",
      "Epoch 452/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3135 - val_loss: 0.3198\n",
      "Epoch 453/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3131 - val_loss: 0.3173\n",
      "Epoch 454/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3128 - val_loss: 0.3180\n",
      "Epoch 455/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3135 - val_loss: 0.3193\n",
      "Epoch 456/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3132 - val_loss: 0.3170\n",
      "Epoch 457/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3139 - val_loss: 0.3173\n",
      "Epoch 458/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3138 - val_loss: 0.3198\n",
      "Epoch 459/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3146 - val_loss: 0.3177\n",
      "Epoch 460/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3123 - val_loss: 0.3169\n",
      "Epoch 461/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3131 - val_loss: 0.3174\n",
      "Epoch 462/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3128 - val_loss: 0.3209\n",
      "Epoch 463/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3128 - val_loss: 0.3236\n",
      "Epoch 464/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3136 - val_loss: 0.3177\n",
      "Epoch 465/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3127 - val_loss: 0.3218\n",
      "Epoch 466/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3129 - val_loss: 0.3173\n",
      "Epoch 467/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3121 - val_loss: 0.3178\n",
      "Epoch 468/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3120 - val_loss: 0.3181\n",
      "Epoch 469/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3134 - val_loss: 0.3174\n",
      "Epoch 470/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3113 - val_loss: 0.3188\n",
      "Epoch 471/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3126 - val_loss: 0.3252\n",
      "Epoch 472/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3149 - val_loss: 0.3215\n",
      "Epoch 473/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3131 - val_loss: 0.3162\n",
      "Epoch 474/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3110 - val_loss: 0.3184\n",
      "Epoch 475/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3110 - val_loss: 0.3170\n",
      "Epoch 476/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3113 - val_loss: 0.3172\n",
      "Epoch 477/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3113 - val_loss: 0.3169\n",
      "Epoch 478/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3113 - val_loss: 0.3163\n",
      "Epoch 479/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3109 - val_loss: 0.3191\n",
      "Epoch 480/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3119 - val_loss: 0.3174\n",
      "Epoch 481/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3120 - val_loss: 0.3181\n",
      "Epoch 482/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3116 - val_loss: 0.3191\n",
      "Epoch 483/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3105 - val_loss: 0.3151\n",
      "Epoch 484/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3108 - val_loss: 0.3153\n",
      "Epoch 485/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3120 - val_loss: 0.3265\n",
      "Epoch 486/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3113 - val_loss: 0.3183\n",
      "Epoch 487/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3113 - val_loss: 0.3179\n",
      "Epoch 488/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3126 - val_loss: 0.3154\n",
      "Epoch 489/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3103 - val_loss: 0.3169\n",
      "Epoch 490/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3109 - val_loss: 0.3192\n",
      "Epoch 491/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3104 - val_loss: 0.3180\n",
      "Epoch 492/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3108 - val_loss: 0.3168\n",
      "Epoch 493/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3102 - val_loss: 0.3157\n",
      "Epoch 494/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3121 - val_loss: 0.3159\n",
      "Epoch 495/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3106 - val_loss: 0.3167\n",
      "Epoch 496/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3112 - val_loss: 0.3141\n",
      "Epoch 497/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3098 - val_loss: 0.3158\n",
      "Epoch 498/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3113 - val_loss: 0.3185\n",
      "Epoch 499/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3101 - val_loss: 0.3218\n",
      "Epoch 500/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3099 - val_loss: 0.3163\n",
      "Epoch 501/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3106 - val_loss: 0.3163\n",
      "Epoch 502/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3099 - val_loss: 0.3162\n",
      "Epoch 503/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3101 - val_loss: 0.3138\n",
      "Epoch 504/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3093 - val_loss: 0.3142\n",
      "Epoch 505/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3092 - val_loss: 0.3163\n",
      "Epoch 506/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3102 - val_loss: 0.3168\n",
      "Epoch 507/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3091 - val_loss: 0.3143\n",
      "Epoch 508/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3094 - val_loss: 0.3159\n",
      "Epoch 509/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3088 - val_loss: 0.3169\n",
      "Epoch 510/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3103 - val_loss: 0.3136\n",
      "Epoch 511/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3098 - val_loss: 0.3144\n",
      "Epoch 512/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3088 - val_loss: 0.3173\n",
      "Epoch 513/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3094 - val_loss: 0.3129\n",
      "Epoch 514/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3082 - val_loss: 0.3158\n",
      "Epoch 515/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3092 - val_loss: 0.3152\n",
      "Epoch 516/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3086 - val_loss: 0.3141\n",
      "Epoch 517/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3080 - val_loss: 0.3204\n",
      "Epoch 518/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3107 - val_loss: 0.3146\n",
      "Epoch 519/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3082 - val_loss: 0.3152\n",
      "Epoch 520/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3081 - val_loss: 0.3170\n",
      "Epoch 521/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3101 - val_loss: 0.3156\n",
      "Epoch 522/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3090 - val_loss: 0.3137\n",
      "Epoch 523/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3073 - val_loss: 0.3128\n",
      "Epoch 524/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3082 - val_loss: 0.3138\n",
      "Epoch 525/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3094 - val_loss: 0.3130\n",
      "Epoch 526/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3078 - val_loss: 0.3144\n",
      "Epoch 527/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3082 - val_loss: 0.3120\n",
      "Epoch 528/2000\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3074 - val_loss: 0.3128\n",
      "Epoch 529/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3078 - val_loss: 0.3181\n",
      "Epoch 530/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3076 - val_loss: 0.3167\n",
      "Epoch 531/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3076 - val_loss: 0.3127\n",
      "Epoch 532/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3072 - val_loss: 0.3216\n",
      "Epoch 533/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3084 - val_loss: 0.3140\n",
      "Epoch 534/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3066 - val_loss: 0.3126\n",
      "Epoch 535/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3082 - val_loss: 0.3141\n",
      "Epoch 536/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3106 - val_loss: 0.3158\n",
      "Epoch 537/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3073 - val_loss: 0.3124\n",
      "Epoch 538/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3062 - val_loss: 0.3134\n",
      "Epoch 539/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3067 - val_loss: 0.3123\n",
      "Epoch 540/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3069 - val_loss: 0.3129\n",
      "Epoch 541/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3074 - val_loss: 0.3117\n",
      "Epoch 542/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3064 - val_loss: 0.3138\n",
      "Epoch 543/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3062 - val_loss: 0.3118\n",
      "Epoch 544/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3061 - val_loss: 0.3121\n",
      "Epoch 545/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3064 - val_loss: 0.3121\n",
      "Epoch 546/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3057 - val_loss: 0.3139\n",
      "Epoch 547/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3064 - val_loss: 0.3195\n",
      "Epoch 548/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3096 - val_loss: 0.3164\n",
      "Epoch 549/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3070 - val_loss: 0.3108\n",
      "Epoch 550/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3058 - val_loss: 0.3117\n",
      "Epoch 551/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3064 - val_loss: 0.3117\n",
      "Epoch 552/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3062 - val_loss: 0.3119\n",
      "Epoch 553/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3056 - val_loss: 0.3119\n",
      "Epoch 554/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3059 - val_loss: 0.3106\n",
      "Epoch 555/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3055 - val_loss: 0.3130\n",
      "Epoch 556/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3050 - val_loss: 0.3123\n",
      "Epoch 557/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3050 - val_loss: 0.3101\n",
      "Epoch 558/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3067 - val_loss: 0.3156\n",
      "Epoch 559/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3057 - val_loss: 0.3097\n",
      "Epoch 560/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3048 - val_loss: 0.3101\n",
      "Epoch 561/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3048 - val_loss: 0.3114\n",
      "Epoch 562/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3060 - val_loss: 0.3111\n",
      "Epoch 563/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3041 - val_loss: 0.3093\n",
      "Epoch 564/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3046 - val_loss: 0.3136\n",
      "Epoch 565/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3054 - val_loss: 0.3181\n",
      "Epoch 566/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3056 - val_loss: 0.3141\n",
      "Epoch 567/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3061 - val_loss: 0.3114\n",
      "Epoch 568/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3054 - val_loss: 0.3125\n",
      "Epoch 569/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3051 - val_loss: 0.3096\n",
      "Epoch 570/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3039 - val_loss: 0.3110\n",
      "Epoch 571/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3040 - val_loss: 0.3084\n",
      "Epoch 572/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3038 - val_loss: 0.3110\n",
      "Epoch 573/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3059 - val_loss: 0.3161\n",
      "Epoch 574/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3052 - val_loss: 0.3107\n",
      "Epoch 575/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3060 - val_loss: 0.3107\n",
      "Epoch 576/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3050 - val_loss: 0.3108\n",
      "Epoch 577/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3062 - val_loss: 0.3102\n",
      "Epoch 578/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3038 - val_loss: 0.3092\n",
      "Epoch 579/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3053 - val_loss: 0.3091\n",
      "Epoch 580/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3028 - val_loss: 0.3089\n",
      "Epoch 581/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3038 - val_loss: 0.3098\n",
      "Epoch 582/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3037 - val_loss: 0.3229\n",
      "Epoch 583/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3059 - val_loss: 0.3115\n",
      "Epoch 584/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3047 - val_loss: 0.3095\n",
      "Epoch 585/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3031 - val_loss: 0.3082\n",
      "Epoch 586/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3027 - val_loss: 0.3112\n",
      "Epoch 587/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3034 - val_loss: 0.3086\n",
      "Epoch 588/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3028 - val_loss: 0.3121\n",
      "Epoch 589/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3030 - val_loss: 0.3101\n",
      "Epoch 590/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3024 - val_loss: 0.3077\n",
      "Epoch 591/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3023 - val_loss: 0.3080\n",
      "Epoch 592/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3036 - val_loss: 0.3100\n",
      "Epoch 593/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3025 - val_loss: 0.3085\n",
      "Epoch 594/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3035 - val_loss: 0.3093\n",
      "Epoch 595/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3025 - val_loss: 0.3083\n",
      "Epoch 596/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3017 - val_loss: 0.3110\n",
      "Epoch 597/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3028 - val_loss: 0.3127\n",
      "Epoch 598/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3029 - val_loss: 0.3109\n",
      "Epoch 599/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3036 - val_loss: 0.3076\n",
      "Epoch 600/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3020 - val_loss: 0.3084\n",
      "Epoch 601/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3024 - val_loss: 0.3074\n",
      "Epoch 602/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3022 - val_loss: 0.3115\n",
      "Epoch 603/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3025 - val_loss: 0.3075\n",
      "Epoch 604/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3017 - val_loss: 0.3077\n",
      "Epoch 605/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3047 - val_loss: 0.3076\n",
      "Epoch 606/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3013 - val_loss: 0.3099\n",
      "Epoch 607/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3018 - val_loss: 0.3125\n",
      "Epoch 608/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3054 - val_loss: 0.3070\n",
      "Epoch 609/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3010 - val_loss: 0.3101\n",
      "Epoch 610/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3025 - val_loss: 0.3091\n",
      "Epoch 611/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3022 - val_loss: 0.3067\n",
      "Epoch 612/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3010 - val_loss: 0.3079\n",
      "Epoch 613/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3017 - val_loss: 0.3078\n",
      "Epoch 614/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3021 - val_loss: 0.3081\n",
      "Epoch 615/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3018 - val_loss: 0.3078\n",
      "Epoch 616/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3019 - val_loss: 0.3068\n",
      "Epoch 617/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3021 - val_loss: 0.3068\n",
      "Epoch 618/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3019 - val_loss: 0.3111\n",
      "Epoch 619/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3017 - val_loss: 0.3081\n",
      "Epoch 620/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3009 - val_loss: 0.3069\n",
      "Epoch 621/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3006 - val_loss: 0.3084\n",
      "Epoch 622/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3027 - val_loss: 0.3062\n",
      "Epoch 623/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3003 - val_loss: 0.3071\n",
      "Epoch 624/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3005 - val_loss: 0.3053\n",
      "Epoch 625/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3006 - val_loss: 0.3085\n",
      "Epoch 626/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3018 - val_loss: 0.3054\n",
      "Epoch 627/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3009 - val_loss: 0.3052\n",
      "Epoch 628/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3029 - val_loss: 0.3085\n",
      "Epoch 629/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3009 - val_loss: 0.3058\n",
      "Epoch 630/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2999 - val_loss: 0.3054\n",
      "Epoch 631/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3004 - val_loss: 0.3160\n",
      "Epoch 632/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3016 - val_loss: 0.3071\n",
      "Epoch 633/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3005 - val_loss: 0.3083\n",
      "Epoch 634/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3000 - val_loss: 0.3082\n",
      "Epoch 635/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3007 - val_loss: 0.3064\n",
      "Epoch 636/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2989 - val_loss: 0.3052\n",
      "Epoch 637/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3000 - val_loss: 0.3059\n",
      "Epoch 638/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2998 - val_loss: 0.3097\n",
      "Epoch 639/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3005 - val_loss: 0.3049\n",
      "Epoch 640/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2997 - val_loss: 0.3053\n",
      "Epoch 641/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3000 - val_loss: 0.3057\n",
      "Epoch 642/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3000 - val_loss: 0.3058\n",
      "Epoch 643/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2997 - val_loss: 0.3042\n",
      "Epoch 644/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3001 - val_loss: 0.3055\n",
      "Epoch 645/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2991 - val_loss: 0.3045\n",
      "Epoch 646/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3001 - val_loss: 0.3175\n",
      "Epoch 647/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3010 - val_loss: 0.3057\n",
      "Epoch 648/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2994 - val_loss: 0.3059\n",
      "Epoch 649/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2999 - val_loss: 0.3078\n",
      "Epoch 650/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3001 - val_loss: 0.3111\n",
      "Epoch 651/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2996 - val_loss: 0.3045\n",
      "Epoch 652/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2994 - val_loss: 0.3046\n",
      "Epoch 653/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2996 - val_loss: 0.3100\n",
      "Epoch 654/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2990 - val_loss: 0.3056\n",
      "Epoch 655/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2991 - val_loss: 0.3045\n",
      "Epoch 656/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2992 - val_loss: 0.3157\n",
      "Epoch 657/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2999 - val_loss: 0.3031\n",
      "Epoch 658/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2981 - val_loss: 0.3074\n",
      "Epoch 659/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2999 - val_loss: 0.3088\n",
      "Epoch 660/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2985 - val_loss: 0.3037\n",
      "Epoch 661/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2987 - val_loss: 0.3094\n",
      "Epoch 662/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3001 - val_loss: 0.3043\n",
      "Epoch 663/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2985 - val_loss: 0.3047\n",
      "Epoch 664/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2989 - val_loss: 0.3032\n",
      "Epoch 665/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2982 - val_loss: 0.3073\n",
      "Epoch 666/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2984 - val_loss: 0.3029\n",
      "Epoch 667/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2976 - val_loss: 0.3048\n",
      "Epoch 668/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2982 - val_loss: 0.3035\n",
      "Epoch 669/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2985 - val_loss: 0.3118\n",
      "Epoch 670/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2999 - val_loss: 0.3040\n",
      "Epoch 671/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2972 - val_loss: 0.3038\n",
      "Epoch 672/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2987 - val_loss: 0.3081\n",
      "Epoch 673/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2987 - val_loss: 0.3074\n",
      "Epoch 674/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2974 - val_loss: 0.3030\n",
      "Epoch 675/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2986 - val_loss: 0.3050\n",
      "Epoch 676/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2985 - val_loss: 0.3069\n",
      "Epoch 677/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2974 - val_loss: 0.3062\n",
      "Epoch 678/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2982 - val_loss: 0.3039\n",
      "Epoch 679/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2976 - val_loss: 0.3053\n",
      "Epoch 680/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2978 - val_loss: 0.3035\n",
      "Epoch 681/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2980 - val_loss: 0.3051\n",
      "Epoch 682/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2979 - val_loss: 0.3021\n",
      "Epoch 683/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2970 - val_loss: 0.3035\n",
      "Epoch 684/2000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2969 - val_loss: 0.3022\n",
      "Epoch 685/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2967 - val_loss: 0.3014\n",
      "Epoch 686/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2967 - val_loss: 0.3028\n",
      "Epoch 687/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2965 - val_loss: 0.3036\n",
      "Epoch 688/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2972 - val_loss: 0.3048\n",
      "Epoch 689/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2972 - val_loss: 0.3021\n",
      "Epoch 690/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2962 - val_loss: 0.3014\n",
      "Epoch 691/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2961 - val_loss: 0.3093\n",
      "Epoch 692/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2994 - val_loss: 0.3078\n",
      "Epoch 693/2000\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2972 - val_loss: 0.3041\n",
      "Epoch 694/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2974 - val_loss: 0.3013\n",
      "Epoch 695/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2963 - val_loss: 0.3035\n",
      "Epoch 696/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2962 - val_loss: 0.3018\n",
      "Epoch 697/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2955 - val_loss: 0.3012\n",
      "Epoch 698/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2962 - val_loss: 0.3025\n",
      "Epoch 699/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2959 - val_loss: 0.3015\n",
      "Epoch 700/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2957 - val_loss: 0.3014\n",
      "Epoch 701/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2978 - val_loss: 0.3029\n",
      "Epoch 702/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2964 - val_loss: 0.3039\n",
      "Epoch 703/2000\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2963 - val_loss: 0.3009\n",
      "Epoch 704/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2972 - val_loss: 0.3021\n",
      "Epoch 705/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2969 - val_loss: 0.3026\n",
      "Epoch 706/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2974 - val_loss: 0.3013\n",
      "Epoch 707/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2958 - val_loss: 0.3014\n",
      "Epoch 708/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2958 - val_loss: 0.3018\n",
      "Epoch 709/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2971 - val_loss: 0.3026\n",
      "Epoch 710/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2955 - val_loss: 0.2999\n",
      "Epoch 711/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2960 - val_loss: 0.3019\n",
      "Epoch 712/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2953 - val_loss: 0.3095\n",
      "Epoch 713/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2966 - val_loss: 0.3004\n",
      "Epoch 714/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2953 - val_loss: 0.3006\n",
      "Epoch 715/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2946 - val_loss: 0.3000\n",
      "Epoch 716/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2951 - val_loss: 0.3013\n",
      "Epoch 717/2000\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2948 - val_loss: 0.3047\n",
      "Epoch 718/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2954 - val_loss: 0.3052\n",
      "Epoch 719/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2953 - val_loss: 0.3001\n",
      "Epoch 720/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2951 - val_loss: 0.3020\n",
      "Epoch 721/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2969 - val_loss: 0.3008\n",
      "Epoch 722/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2954 - val_loss: 0.3027\n",
      "Epoch 723/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2956 - val_loss: 0.3006\n",
      "Epoch 724/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2961 - val_loss: 0.3019\n",
      "Epoch 725/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2950 - val_loss: 0.3003\n",
      "Epoch 726/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2960 - val_loss: 0.3017\n",
      "Epoch 727/2000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2962 - val_loss: 0.3006\n",
      "Epoch 728/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2950 - val_loss: 0.3071\n",
      "Epoch 729/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2957 - val_loss: 0.3003\n",
      "Epoch 730/2000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2942 - val_loss: 0.3033\n",
      "Epoch 730: early stopping\n",
      "122.01017951965332\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "history = model.fit(X_train,y_train,epochs=2000,callbacks=callback,initial_epoch=10,batch_size=2500,validation_split=0.2)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae227ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9640407713436967"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred= model.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb527567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x137116dc430>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeKUlEQVR4nO3de5AdZ5nf8e/T5zo3zUiasSxLsiRj2ebmCwhjLywxa5bYjguyARIbCgjFrqtY/oBkKwksFfZSlUqxqSIssIXXCw6QENbEEOJ1cVmDHS4BDCMj+SLZsuSbJEuakUZzOTPn2v3kj+4ZzYyONGNpRuf0+PepOnX6dPecfjRH8+u33367j7k7IiKSfkGrCxARkaWhQBcRWSEU6CIiK4QCXURkhVCgi4isENlWbbi/v9+3bNnSqs2LiKTSjh07jrn7QLNlLQv0LVu2MDg42KrNi4ikkpk9f7pl6nIREVkhFOgiIiuEAl1EZIVQoIuIrBALBrqZFc3s12a2y8yeMLO/aLJOwczuMbN9ZvawmW1ZlmpFROS0FtNCrwK/5+5XAVcDN5nZdfPW+TBwwt0vBf4r8JklrVJERBa0YKB7rJS8zCWP+bdofCfwtWT6XuBGM7Mlq1JERBa0qD50M8uY2U5gCHjA3R+et8oG4ACAuzeAMWBtk/e5w8wGzWxweHj4rAree3SCz/7jUxwrVc/q50VEVqpFBbq7h+5+NbARuNbMXnM2G3P3u9x9u7tvHxhoeqHTgvYNlfj8g/sYmayd1c+LiKxUL2mUi7uPAg8BN81bdAjYBGBmWaAXOL4E9Z0iSDpyIn0xh4jIHIsZ5TJgZn3JdAfw+8CT81a7D/hgMv1u4EFfpq9Cmu6aj6LleHcRkfRazL1c1gNfM7MM8Q7gW+5+v5n9JTDo7vcBXwH+u5ntA0aA25ar4GA60NVCFxGZY8FAd/dHgWuazP/0rOkK8J6lLa256S4X5bmIyFypu1JULXQRkeZSF+imk6IiIk2lLtBPttBbXIiISJtJbaAv0yAaEZHUSmGgx89qoYuIzJW6QDedFBURaSp1ga4rRUVEmktfoAe6UlREpJn0Bbpa6CIiTaUu0NWHLiLSXOoC/eSwxRYXIiLSZlIY6PGzWugiInOlMNB1paiISDMpDnQluojIbOkL9KRiXfovIjJX+gJdXS4iIk2lMNDjZ3W5iIjMlbpAN7XQRUSaSl2g6/a5IiLNpTDQ42d1uYiIzJXCQNfNuUREmkldoE9/p2ioFrqIyBypC/QAyBDiaqKLiMyRukDvfPof2F98P90Tz7S6FBGRtpK6QLeZS0UbrS1ERKTNpC7QCTIAuAaii4jMkbpAP9lCD1tbiIhIm0ldoAdBFgAPFegiIrMtGOhmtsnMHjKz3Wb2hJl9rMk6N5jZmJntTB6fXp5ywWy6ha5RLiIis2UXsU4D+BN3f8TMeoAdZvaAu++et97P3P3WpS9xnkzSh64uFxGRORZsobv7YXd/JJmeAPYAG5a7sNMJpvvQNQ5dRGSOl9SHbmZbgGuAh5ssvt7MdpnZ983s1af5+TvMbNDMBoeHh196tZzsQydSC11EZLZFB7qZdQPfBj7u7uPzFj8CbHb3q4AvAN9t9h7ufpe7b3f37QMDA2dZ8XSXi1roIiKzLSrQzSxHHObfcPfvzF/u7uPuXkqmvwfkzKx/SStNBBq2KCLS1GJGuRjwFWCPu3/2NOtcmKyHmV2bvO/xpSx0ZlszFxaphS4iMttiRrm8CXg/8JiZ7Uzm/SlwMYC73wm8G/iImTWAMnCbL9M3UARJoKsPXURkrgUD3d1/DtgC63wR+OJSFXUm0y10jUMXEZkrdVeK6tJ/EZHmUhfomLpcRESaSV+gq8tFRKSp9AW67uUiItJUCgNdLXQRkWZSGOg6KSoi0kz6Aj1Ql4uISDPpC/TpFrpGuYiIzJHCQI/70G15LkQVEUmtFAa6+tBFRJpJX6DrXi4iIk2lL9A1bFFEpKkUBnpcsr5TVERkrvQFejJsUfdDFxGZK32BnrTQTS10EZE5Uhjo+k5REZFmUhjoSQtdXS4iInOkL9Bnbp/baG0dIiJtJn2BPj3KJdKVoiIis6Uw0JNL/9FJURGR2dIX6NN3W1QfuojIHOkLdCAk0L1cRETmSWWgO4Eu/RcRmSeVgR5hmAJdRGSOdAa6qYUuIjJfKgPd1YcuInKK1Aa6ulxEROZaMNDNbJOZPWRmu83sCTP7WJN1zMw+b2b7zOxRM3vd8pQbi0yBLiIyX3YR6zSAP3H3R8ysB9hhZg+4++5Z69wMbEsebwS+lDwvC3W5iIicasEWursfdvdHkukJYA+wYd5q7wS+7rFfAX1mtn7Jq01EllELXURknpfUh25mW4BrgIfnLdoAHJj1+iCnhv6SiSxDoEv/RUTmWHSgm1k38G3g4+4+fjYbM7M7zGzQzAaHh4fP5i2AONAzutuiiMgciwp0M8sRh/k33P07TVY5BGya9XpjMm8Od7/L3be7+/aBgYGzqReAiAyB+tBFROZYzCgXA74C7HH3z55mtfuADySjXa4Dxtz98BLWOUcUZBXoIiLzLGaUy5uA9wOPmdnOZN6fAhcDuPudwPeAW4B9wBTwoSWvdBa10EVETrVgoLv7zwFbYB0HPrpURS0kCrJkdFJURGSOdF4pqpOiIiKnSGWgR5bVsEURkXlSGehxC10XFomIzJbOQA/UQhcRmS+VgR5fWKRAFxGZLZWB7pYhi06KiojMls5AD7JkUB+6iMhs6Qx0i8ehh5G3uhQRkbaRykAnyJIlpBGplS4iMi2lgZ6JAz1UC11EZFoqA92DLBmLFOgiIrOkMtAtyJElpK4uFxGRGakMdJKbc6mFLiJyUjoDPZMlS0Q9VAtdRGRaKgPdpk+KatiiiMiMVAY6mVwyykUtdBGRaakMdEv60OvqQxcRmZHOQM/kyBLpwiIRkVlSGugZAnPqdd2gS0RkWkoDvQBAWK+2uBIRkfaRzkDP5gGIGgp0EZFpKQ30IqAWuojIbKkM9CCbAyBSoIuIzEhloE+30L1RaXElIiLtI5WBHuR0UlREZL5UB7o3ai2uRESkfaQz0DXKRUTkFKkM9Ewu7kNHXS4iIjMWDHQzu9vMhszs8dMsv8HMxsxsZ/L49NKXOVeQT7pcQgW6iMi07CLW+SrwReDrZ1jnZ+5+65JUtAjZpIXuaqGLiMxYsIXu7j8FRs5DLYuWK3QAEIU6KSoiMm2p+tCvN7NdZvZ9M3v16VYyszvMbNDMBoeHh896Y7lklIsuLBIROWkpAv0RYLO7XwV8Afju6VZ097vcfbu7bx8YGDjrDU4PW0SjXEREZpxzoLv7uLuXkunvATkz6z/nys4kOz0OXYEuIjLtnAPdzC40M0umr03e8/i5vu8ZZeJx6LqwSETkpAVHuZjZN4EbgH4zOwj8GZADcPc7gXcDHzGzBlAGbnP35f1uuKSFjk6KiojMWDDQ3f32BZZ/kXhY4/mTtNDROHQRkRmpvFKUIEuEYWqhi4jMSGegm1Enpy4XEZFZ0hnoQMNyBAp0EZEZKQ70LEGkQBcRmZbaQA8tr0AXEZkltYHeCHJYVG91GSIibSO1gR5anowCXURkRmoDPQpyZNXlIiIyI9WBnnG10EVEpqU40PMKdBGRWVIb6J7Jk1Ogi4jMSHGgF8hRpxFGrS5FRKQtpDbQo0yePA1qCnQRESDFgU4mR5461boCXUQEUhzonu2kw2pqoYuIJNIb6LlOOqmqhS4ikkhtoJPrpEiVaiNsdSUiIm0hvYGe7yRvIdWavrVIRARSHOiW7wKgUS61uBIRkfaQ/kCvKtBFRCDFgR4Uplvoky2uRESkPaQ20PPFbgDqFbXQRUQgzYHemQS6+tBFRIAUB3qhQy10EZHZUhvoxa4eAKKq+tBFRCDFgT7dhx5qlIuICJDiQCcZtug1tdBFRCDNgZ7rjJ9rU62tQ0SkTSwY6GZ2t5kNmdnjp1luZvZ5M9tnZo+a2euWvswmkhY6dQW6iAgsroX+VeCmMyy/GdiWPO4AvnTuZS1CkKFGDlOgi4gAiwh0d/8pMHKGVd4JfN1jvwL6zGz9UhV4JtWgSKZRPh+bEhFpe0vRh74BODDr9cFk3inM7A4zGzSzweHh4XPecM06yIRqoYuIwHk+Kerud7n7dnffPjAwcM7v18gUyYZqoYuIwNIE+iFg06zXG5N5y66R6SAfVc7HpkRE2t5SBPp9wAeS0S7XAWPufngJ3ndBtVwPHZHGoYuIAGQXWsHMvgncAPSb2UHgz4AcgLvfCXwPuAXYB0wBH1quYudr5FbR44cJIycT2PnarIhIW1ow0N399gWWO/DRJavoJQgLvfTZFFO1Bj3FXCtKEBFpG+m9UhSICr30MslUTV8ULSKS6kC3jj46rMZESTfoEhFJdaDnuvoAKI0db20hIiJtINWBnu9aA8DU2JkuZBUReXlIdaAXe+JAr5ROtLgSEZHWS3Wgd/auBaBWUpeLiEi6A31VHOiNqdHWFiIi0gZSHehBRx8AkQJdRCTdgU6xN36ujLW2DhGRNpDuQM8VqZInUx1tdSUiIi2X7kAHJjJ9dNQ0bFFEJPWBXsqtpad+rNVliIi0XOoDvVwYoC9SC11EJPWBXu+4gLV+glojanUpIiItlfpAp2cda6zEsbGJVlciItJSqQ/0XO96AEaOHlhgTRGRlS31gd6xZgMApWPn5WtMRUTaVuoDfdUFGwGYGlGgi8jLW+oDffW6iwGoHVeXi4i8vKU+0K17HZN0kh/d3+pSRERaKvWBjhlDhYvpm3q21ZWIiLRU+gMdKK+5gksa+xkpVVpdiohIy6yIQC9uvZ4+m+TJx3e0uhQRkZZZEYG+4Zp/CkD1iftbXImISOusiEAvDGzl6dzlbDj0A6LIW12OiEhLrIhAByhf/s+5LHqGvT/+aqtLERFpiRUT6Jfd+m/Yy2a6f/lfqE3pvi4i8vKzYgK9WOxg/Hf/I+vDF3nu794LYaPVJYmInFeLCnQzu8nMnjKzfWb2iSbL/7WZDZvZzuTxh0tf6sK23/ge7r/oY1x24qcc+NyN+HFdbCQiLx8LBrqZZYC/AW4GXgXcbmavarLqPe5+dfL48hLXuWi3/tGfc8/GT7FqfC+lL76FkUd/0KpSRETOq8W00K8F9rn7M+5eA/4eeOfylnX2MoHxLz/87/jJW+/lSNTHmu/8K579wjupHfxtq0sTEVlWiwn0DcDsO18dTObN9y4ze9TM7jWzTc3eyMzuMLNBMxscHh4+i3IXx8x4xw1vovDHP+G+1R9k9bHfkP/yDTx353uoHt6zbNsVEWmlpTop+g/AFne/EngA+Fqzldz9Lnff7u7bBwYGlmjTp3fxun7e8bHPs/tdD/Ldjn/B2sM/I/e31/P8X99M5Qd/DsN7l70GEZHzJbuIdQ4Bs1vcG5N5M9z9+KyXXwb+6txLWzq/c+UV+GvvZsfuvRz44Re4fuR+ir/6BVO//juOX/E+Nrz5fQTrrwSzVpcqInLWzP3MV1aaWRbYC9xIHOS/Ad7r7k/MWme9ux9Opv8A+A/uft2Z3nf79u0+ODh4juWfnT0Hj/PIQ99m6/7/wbX+GFmLGCusp7H5n7B6+3sIcgW48DXQsbol9YmInI6Z7XD37U2XLRToyRvcAnwOyAB3u/t/MrO/BAbd/T4z+8/AO4AGMAJ8xN2fPNN7tjLQp1XqIT/Z+SSHfvktLjv2I66z3WQtAmAqv5b6+u3Ytrexat0lcOmNasGLSMudc6Avh3YI9NmOlar8avezHNnzC8ZeeIxb6j/ilcELM8urmW6mVl+OX3YTq4d+g22+Dq55P3Rf0MKqReTlRoF+Fp49Nsmu54/ywmO/JHP4ETZNPcEbgqdYbyNz1hvt2IR39hNsfD1day4i2/8KyORh1XqYOg6vUMteRJaOAn0JHCtV2Xt4nKNHDvDci0eZOrqPvtHdXF7fwzo7wVY7Qred+gUbEx0bqKy+nK7yi9C7ifyFl5O96Ko47HOdcNlNkCtCFEKxF4JMC/51IpIWZwr0xYxyEaC/u0D/tgHYNne45Xilzv6hEt8bKjF07Di1oacZHR+nY/xZeqeeZ2vpMJdN7qHTRghHXqDzuQdOeW/HMJzJ4joqfdvIRRW8+0I6pw7hl91E/uguGH4S3vop6OqHIAuda6H/Mji8C8YOwuY3QUcf7H8QLrkBLAB3iOqQ65i7wSiCYMXcxkdEEmqhL6Mocg6cmGJkssboVJ3jpSoHh4apDD/L2NgEhdoIvaX95MMSW3iRLBGb7SghAevsBH2UZk7SvhSTqy7Bghydo08BULvoDdQ3/Q4d+QKBN+DRe+CKW+HSt0F1PN4xTA7HOwSAC6+ETC6erpbiHcLzv4BN10K2cOaNH9oBA6+EfOdLrltEFqYulzbXCCOqjYjRcp2h8QqVesSJqRrDE1UaU6NMTYxSroesGn+aci0krJZ4Rfkxyg0YbeTZ6i/QTZmNNszW4CiHfQ0FagQ4fTbJkPfRzxiBLf6znsqtwYjoqI9Sy3SRDyfjWnPdTPVuI9Pdj/duIpPvIFPoIpPNEUwcxnbcHb/BpW+DV/8BrLoIxg/HQ0B3fRO2vR3WXAL1MmSysOmN8RFHJgf1StzlNL0zWQx3naOQlxUF+go3/S1N9SjieKnG4bEKY+UaF/V18NSRCcbLddwjXhytUvApqmNDZMeep9iY4LCvZXXtRTrrJ6hERq1Wpz88SjdlDJiiQL+NscmGea09w0EfYIoia2ycIjUK1Cla/Zz/DbWgk3w0BcBocSOeKWBmmIdUcn0EmSwUummQpVA5hmXzrB56GIBK1wYyRIxtvYUo10WvTeLDT5O56Erq2S46R/bA+quITryAFbqJjj9DjQzFi16NlU/Ar++CN/wRbP1dKJ+AtdvghV/C+qvggleBhzA1Eu94etbHO5BMDsqj8dFLthjvoB77FuS7YfXmuNsL4nMj9TJUJ+Kf717CK6SjCMJafA5mtnol7mor9CzdtqRtKNDlJXF3amFErRF395SqDQIzDo9VmKw2MIOh8SqVekgtjKhWKzRqdaLaFI3qJOPVCKIGhfo4HfURJuhibe1FjgYDrKu+QBiFPF/potYIebU/TSnMMuAjXGCjBEQERDTIUqRKgNNlZQKcAnXW2DghGSqeZ0twFIAh7+MCGyV0w7Gz6qZaag3LkfVTd3SlfD/ZqIZblgwNSh0bKXVtwjHcI9aM7aFaWEsxaFDpWEeY6SC0LIR1Mh2r6D/wQzKVE4xuexcdxx8nO3GQya03ke/px6sTUJ+iY/8PsEaZias+TEc4Qa3nYjxbIH90J9kggEvfhkcNLKziBARTx+Id0+GdsOH18U6rZ328Uzj8KPzmK3DFP4ONb4iH6Ra6wYHR5+CZ/wuv/1B8BFYvQ3kEOtZA70Z4/N74XM62twMGL/wCLrs53tbPPwvP/xLee0+8syv0xEdnUQQnnoW+iyGsx1134y9C97q5AwYaNcjm5/5yDw7G6/XNu5XU8F448DBcdXtcT9SAvT+Iux1nn0tq1OJttPnABAW6tD13px461UZIFIHjTNZCcoFRCyMq9YhStUExF5AxY7IWUq6FjFfqhJFTDyO6sjA2OcWJiRKFYjfVyVE8cqpuFMtHmOjcQrYxwXjVyYWTrKkPMRJ2EBVWka8ex6tT5LxCj09xoNHL6sYwnT5J5JD1Bg3LUIgqFL2MOxyp5iGTpVAfJ7QcFlboi0ZZxRQTXqRoNU7QixHxRttDQMTjvpXQAzqsyiqm6LAq/YzN/B56rMxR72PMu7jYhuixMgEREQFFahhO0eqMeycV8lxgo9Q9Q5UckxTJ0WCNlQCI3BiijwsYfUndbcutbjly83Z25WwvmaiGEZGLqjSCAtmoynjhQlZVj8Tr5Pqo5foICOksH2ayaxNRpogFWcJ6hTWlpwGYXHslmdo4teJaah0D9L9w8hbaUaZAEFbnbHtq01uwRpXC8C6iIE/Ys5Go2IflO6GzH+vohd6LsckjZI49iR/djV/yVnLrXgmZPJWpcXL5Ag0yFHK5+DzS0O74OpUjj8KqjdC5Jh7Vtv/HcHw/3PwZuPiMF9OflgJdpAWm/7am/8SCwJisNmhEThQ5peRoByCMnM58FjMoVRocK1XJBEY2CMgERhDAwZHyzPqRx+/fmc8yNBEfOWWCgIAIyiMEnf1MlUtUKBBENbrqx5nMrKHSiFhVPkCULVKtO0FYJtMoU6oHjGT6yDWmWFt08lNDRPUyJ4LV1MOIqF6hOxdQnxqjKxMS1quMBr1M5vp5RfkxKuSgUWFVNEa31RgJizwfDlDN9fBK30+2PgG5TqrkyNXHqYWQL3bRUz3CeFSkzyaoeo6QDHt9I6+wF7ncDjJGFxkixumk4nl6rUQHNTqo0iBDj5VZwzgRxtbgKLuiSyhT4FI7RNkLhAT02iSrrcS+6CJ6bZI+SuQsnDmym/QCXXYy5A96P1lCap6l38bpTJZFbgTmNDw456PAnZs/xNUf+txZ/ayGLYq0gCXpO/ucbVfh5J/c6q78/B8B4iGyW/q7Tpl/xYWrFrnlLQssf80i32exbn/JP+HumNnM0VU2MDKBUa6H1BtOLmvUGw4W36IjnwkIgpPrR+5MVBpU6iGlwOguZNlRqhEY1CoNHncnn42P5g5FTi4TUKmHHDEj9HiHOllrECbnn8LIZ86vB2Y4Tq0Rdzs26lWC6jiN3Cq8NsE4PXRbmUa1TKMRUiwWyYWTeLbI5OQkuahCPSiSiyqM5wZYVRsCIPCQSraH8akqV772Sq5eyo8goUAXkfNuemeXCYzMrD7rznwWpvdzyXNvR/NRT+t7577evPbUneDLja4uERFZIRToIiIrhAJdRGSFUKCLiKwQCnQRkRVCgS4iskIo0EVEVggFuojICtGyS//NbBh4/ix/vB84toTlLKe01Ko6l15aalWdS285a93s7k1v29myQD8XZjZ4unsZtJu01Ko6l15aalWdS69VtarLRURkhVCgi4isEGkN9LtaXcBLkJZaVefSS0utqnPptaTWVPahi4jIqdLaQhcRkXkU6CIiK0TqAt3MbjKzp8xsn5l9osW13G1mQ2b2+Kx5a8zsATN7Onlencw3M/t8UvejZva681jnJjN7yMx2m9kTZvaxNq61aGa/NrNdSa1/kczfamYPJzXdY2b5ZH4heb0vWb7lfNWabD9jZr81s/vbtU4ze87MHjOznWY2mMxru88+2X6fmd1rZk+a2R4zu77dajWzy5Pf5fRj3Mw+3hZ1untqHkAG2A9cQvx9JruAV7WwnrcArwMenzXvr4BPJNOfAD6TTN8CfB8w4Drg4fNY53rgdcl0D7AXeFWb1mpAdzKdAx5OavgWcFsy/07gI8n0HwN3JtO3Afec5/8D/xb4n8D9yeu2qxN4DuifN6/tPvtk+18D/jCZzgN97VprUkMGOAJsboc6z+s/fgl+edcDP5z1+pPAJ1tc05Z5gf4UsD6ZXg88lUz/LXB7s/VaUPP/AX6/3WsFOoFHgDcSX3WXnf//APghcH0ynU3Ws/NU30bgx8DvAfcnf7DtWGezQG+7zx7oBZ6d/3tpx1pnbfPtwP9rlzrT1uWyATgw6/XBZF47Wefuh5PpI8C6ZLotak8O9a8hbvm2Za1JN8ZOYAh4gPiobNTdG03qmak1WT4GrD1PpX4O+PfA9FfAr23TOh34RzPbYWZ3JPPa8bPfCgwD/y3pxvqymXW1aa3TbgO+mUy3vM60BXqqeLw7bptxoWbWDXwb+Li7j89e1k61unvo7lcTt4CvBa5obUWnMrNbgSF339HqWhbhze7+OuBm4KNm9pbZC9vos88Sd2F+yd2vASaJuy5mtFGtJOdH3gH8r/nLWlVn2gL9ELBp1uuNybx2ctTM1gMkz0PJ/JbWbmY54jD/hrt/p51rnebuo8BDxF0XfWaWbVLPTK3J8l7g+Hko703AO8zsOeDvibtd/roN68TdDyXPQ8D/Jt5JtuNnfxA46O4PJ6/vJQ74dqwV4h3kI+5+NHnd8jrTFui/AbYlIwnyxIc797W4pvnuAz6YTH+QuL96ev4HkjPe1wFjsw7PlpWZGfAVYI+7f7bNax0ws75kuoO4r38PcbC/+zS1Tv8b3g08mLSOlpW7f9LdN7r7FuL/hw+6+/varU4z6zKznulp4j7fx2nDz97djwAHzOzyZNaNwO52rDVxOye7W6braW2d5/MEwhKdhLiFeJTGfuBTLa7lm8BhoE7cuvgwcb/oj4GngR8Ba5J1DfibpO7HgO3nsc43Ex/+PQrsTB63tGmtVwK/TWp9HPh0Mv8S4NfAPuJD3EIyv5i83pcsv6QF/w9u4OQol7aqM6lnV/J4Yvpvph0/+2T7VwODyef/XWB1O9YKdBEfYfXOmtfyOnXpv4jICpG2LhcRETkNBbqIyAqhQBcRWSEU6CIiK4QCXURkhVCgi4isEAp0EZEV4v8DOWRFCSU7n5QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f298579c",
   "metadata": {},
   "source": [
    "### Custom made ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d4a3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(320,activation='relu',input_dim=X_train.shape[1]))\n",
    "model2.add(Dense(1,activation='linear'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0b15ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 320)               3840      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 321       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,161\n",
      "Trainable params: 4,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3358fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='mean_squared_error',optimizer= opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1af4ce65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "33/33 [==============================] - 1s 11ms/step - loss: 23.0305 - val_loss: 21.5513\n",
      "Epoch 2/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 20.5208 - val_loss: 19.1588\n",
      "Epoch 3/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 18.2048 - val_loss: 16.9510\n",
      "Epoch 4/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 16.0696 - val_loss: 14.9177\n",
      "Epoch 5/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 14.1103 - val_loss: 13.0701\n",
      "Epoch 6/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 12.3435 - val_loss: 11.4132\n",
      "Epoch 7/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 10.7695 - val_loss: 9.9589\n",
      "Epoch 8/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 9.3985 - val_loss: 8.7003\n",
      "Epoch 9/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 8.2294 - val_loss: 7.6379\n",
      "Epoch 10/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 7.2420 - val_loss: 6.7507\n",
      "Epoch 11/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 6.4213 - val_loss: 6.0158\n",
      "Epoch 12/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 5.7444 - val_loss: 5.4064\n",
      "Epoch 13/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 5.1818 - val_loss: 4.9020\n",
      "Epoch 14/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 4.7124 - val_loss: 4.4746\n",
      "Epoch 15/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 4.3160 - val_loss: 4.1150\n",
      "Epoch 16/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 3.9784 - val_loss: 3.8065\n",
      "Epoch 17/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 3.6867 - val_loss: 3.5368\n",
      "Epoch 18/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 3.4300 - val_loss: 3.2979\n",
      "Epoch 19/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 3.2034 - val_loss: 3.0854\n",
      "Epoch 20/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 3.0010 - val_loss: 2.8962\n",
      "Epoch 21/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 2.8191 - val_loss: 2.7237\n",
      "Epoch 22/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 2.6536 - val_loss: 2.5673\n",
      "Epoch 23/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 2.5027 - val_loss: 2.4243\n",
      "Epoch 24/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 2.3636 - val_loss: 2.2919\n",
      "Epoch 25/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 2.2361 - val_loss: 2.1698\n",
      "Epoch 26/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 2.1183 - val_loss: 2.0584\n",
      "Epoch 27/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 2.0101 - val_loss: 1.9549\n",
      "Epoch 28/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 1.9097 - val_loss: 1.8592\n",
      "Epoch 29/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 1.8167 - val_loss: 1.7704\n",
      "Epoch 30/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 1.7304 - val_loss: 1.6879\n",
      "Epoch 31/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 1.6506 - val_loss: 1.6115\n",
      "Epoch 32/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 1.5764 - val_loss: 1.5406\n",
      "Epoch 33/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 1.5075 - val_loss: 1.4749\n",
      "Epoch 34/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 1.4435 - val_loss: 1.4135\n",
      "Epoch 35/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 1.3838 - val_loss: 1.3567\n",
      "Epoch 36/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 1.3285 - val_loss: 1.3037\n",
      "Epoch 37/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 1.2770 - val_loss: 1.2543\n",
      "Epoch 38/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 1.2288 - val_loss: 1.2082\n",
      "Epoch 39/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 1.1839 - val_loss: 1.1656\n",
      "Epoch 40/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 1.1421 - val_loss: 1.1252\n",
      "Epoch 41/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 1.1030 - val_loss: 1.0879\n",
      "Epoch 42/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 1.0665 - val_loss: 1.0532\n",
      "Epoch 43/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 1.0323 - val_loss: 1.0205\n",
      "Epoch 44/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 1.0002 - val_loss: 0.9896\n",
      "Epoch 45/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.9700 - val_loss: 0.9607\n",
      "Epoch 46/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.9417 - val_loss: 0.9335\n",
      "Epoch 47/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.9151 - val_loss: 0.9082\n",
      "Epoch 48/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.8900 - val_loss: 0.8840\n",
      "Epoch 49/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.8663 - val_loss: 0.8613\n",
      "Epoch 50/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.8439 - val_loss: 0.8397\n",
      "Epoch 51/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.8227 - val_loss: 0.8196\n",
      "Epoch 52/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.8026 - val_loss: 0.8000\n",
      "Epoch 53/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.7836 - val_loss: 0.7819\n",
      "Epoch 54/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.7655 - val_loss: 0.7644\n",
      "Epoch 55/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.7482 - val_loss: 0.7479\n",
      "Epoch 56/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.7318 - val_loss: 0.7320\n",
      "Epoch 57/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.7161 - val_loss: 0.7167\n",
      "Epoch 58/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.7011 - val_loss: 0.7024\n",
      "Epoch 59/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.6869 - val_loss: 0.6886\n",
      "Epoch 60/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.6732 - val_loss: 0.6756\n",
      "Epoch 61/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.6602 - val_loss: 0.6629\n",
      "Epoch 62/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.6477 - val_loss: 0.6508\n",
      "Epoch 63/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.6357 - val_loss: 0.6393\n",
      "Epoch 64/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.6243 - val_loss: 0.6283\n",
      "Epoch 65/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.6134 - val_loss: 0.6177\n",
      "Epoch 66/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6029 - val_loss: 0.6074\n",
      "Epoch 67/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.5928 - val_loss: 0.5978\n",
      "Epoch 68/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.5832 - val_loss: 0.5885\n",
      "Epoch 69/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.5740 - val_loss: 0.5797\n",
      "Epoch 70/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.5652 - val_loss: 0.5712\n",
      "Epoch 71/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.5569 - val_loss: 0.5630\n",
      "Epoch 72/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.5489 - val_loss: 0.5555\n",
      "Epoch 73/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.5412 - val_loss: 0.5479\n",
      "Epoch 74/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.5339 - val_loss: 0.5409\n",
      "Epoch 75/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.5269 - val_loss: 0.5341\n",
      "Epoch 76/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.5202 - val_loss: 0.5277\n",
      "Epoch 77/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.5138 - val_loss: 0.5214\n",
      "Epoch 78/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.5077 - val_loss: 0.5156\n",
      "Epoch 79/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.5018 - val_loss: 0.5099\n",
      "Epoch 80/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4962 - val_loss: 0.5046\n",
      "Epoch 81/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4910 - val_loss: 0.4994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4858 - val_loss: 0.4945\n",
      "Epoch 83/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4809 - val_loss: 0.4896\n",
      "Epoch 84/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4762 - val_loss: 0.4852\n",
      "Epoch 85/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.4718 - val_loss: 0.4811\n",
      "Epoch 86/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4675 - val_loss: 0.4767\n",
      "Epoch 87/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4634 - val_loss: 0.4728\n",
      "Epoch 88/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4595 - val_loss: 0.4690\n",
      "Epoch 89/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4557 - val_loss: 0.4653\n",
      "Epoch 90/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.4520 - val_loss: 0.4618\n",
      "Epoch 91/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4486 - val_loss: 0.4584\n",
      "Epoch 92/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4452 - val_loss: 0.4550\n",
      "Epoch 93/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.4419 - val_loss: 0.4519\n",
      "Epoch 94/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.4388 - val_loss: 0.4489\n",
      "Epoch 95/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.4358 - val_loss: 0.4461\n",
      "Epoch 96/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4329 - val_loss: 0.4432\n",
      "Epoch 97/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4302 - val_loss: 0.4406\n",
      "Epoch 98/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.4275 - val_loss: 0.4378\n",
      "Epoch 99/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4249 - val_loss: 0.4353\n",
      "Epoch 100/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.4224 - val_loss: 0.4329\n",
      "Epoch 101/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.4200 - val_loss: 0.4304\n",
      "Epoch 102/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4176 - val_loss: 0.4281\n",
      "Epoch 103/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4154 - val_loss: 0.4260\n",
      "Epoch 104/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.4132 - val_loss: 0.4239\n",
      "Epoch 105/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.4110 - val_loss: 0.4216\n",
      "Epoch 106/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.4090 - val_loss: 0.4196\n",
      "Epoch 107/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.4069 - val_loss: 0.4177\n",
      "Epoch 108/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4050 - val_loss: 0.4158\n",
      "Epoch 109/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4031 - val_loss: 0.4139\n",
      "Epoch 110/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.4013 - val_loss: 0.4123\n",
      "Epoch 111/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3994 - val_loss: 0.4102\n",
      "Epoch 112/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3977 - val_loss: 0.4086\n",
      "Epoch 113/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3960 - val_loss: 0.4069\n",
      "Epoch 114/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3943 - val_loss: 0.4052\n",
      "Epoch 115/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3927 - val_loss: 0.4038\n",
      "Epoch 116/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3911 - val_loss: 0.4021\n",
      "Epoch 117/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3896 - val_loss: 0.4006\n",
      "Epoch 118/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3882 - val_loss: 0.3992\n",
      "Epoch 119/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3867 - val_loss: 0.3976\n",
      "Epoch 120/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3852 - val_loss: 0.3963\n",
      "Epoch 121/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3837 - val_loss: 0.3949\n",
      "Epoch 122/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3823 - val_loss: 0.3938\n",
      "Epoch 123/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3810 - val_loss: 0.3923\n",
      "Epoch 124/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3796 - val_loss: 0.3908\n",
      "Epoch 125/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3783 - val_loss: 0.3894\n",
      "Epoch 126/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3769 - val_loss: 0.3883\n",
      "Epoch 127/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3757 - val_loss: 0.3868\n",
      "Epoch 128/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3744 - val_loss: 0.3857\n",
      "Epoch 129/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3731 - val_loss: 0.3843\n",
      "Epoch 130/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3720 - val_loss: 0.3834\n",
      "Epoch 131/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3707 - val_loss: 0.3821\n",
      "Epoch 132/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3695 - val_loss: 0.3808\n",
      "Epoch 133/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3684 - val_loss: 0.3796\n",
      "Epoch 134/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3671 - val_loss: 0.3785\n",
      "Epoch 135/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3660 - val_loss: 0.3774\n",
      "Epoch 136/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3649 - val_loss: 0.3762\n",
      "Epoch 137/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3637 - val_loss: 0.3751\n",
      "Epoch 138/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3626 - val_loss: 0.3738\n",
      "Epoch 139/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3614 - val_loss: 0.3729\n",
      "Epoch 140/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3604 - val_loss: 0.3715\n",
      "Epoch 141/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3592 - val_loss: 0.3707\n",
      "Epoch 142/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3582 - val_loss: 0.3696\n",
      "Epoch 143/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3570 - val_loss: 0.3682\n",
      "Epoch 144/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3560 - val_loss: 0.3672\n",
      "Epoch 145/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3549 - val_loss: 0.3662\n",
      "Epoch 146/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3538 - val_loss: 0.3652\n",
      "Epoch 147/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3528 - val_loss: 0.3639\n",
      "Epoch 148/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3518 - val_loss: 0.3630\n",
      "Epoch 149/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3507 - val_loss: 0.3621\n",
      "Epoch 150/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3497 - val_loss: 0.3608\n",
      "Epoch 151/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3488 - val_loss: 0.3596\n",
      "Epoch 152/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3475 - val_loss: 0.3589\n",
      "Epoch 153/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3466 - val_loss: 0.3577\n",
      "Epoch 154/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3455 - val_loss: 0.3569\n",
      "Epoch 155/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3445 - val_loss: 0.3558\n",
      "Epoch 156/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3435 - val_loss: 0.3552\n",
      "Epoch 157/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3426 - val_loss: 0.3538\n",
      "Epoch 158/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3415 - val_loss: 0.3528\n",
      "Epoch 159/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.3406 - val_loss: 0.3515\n",
      "Epoch 160/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3396 - val_loss: 0.3505\n",
      "Epoch 161/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.3386 - val_loss: 0.3496\n",
      "Epoch 162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3377 - val_loss: 0.3489\n",
      "Epoch 163/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3367 - val_loss: 0.3478\n",
      "Epoch 164/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3357 - val_loss: 0.3466\n",
      "Epoch 165/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.3348 - val_loss: 0.3456\n",
      "Epoch 166/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3338 - val_loss: 0.3448\n",
      "Epoch 167/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3329 - val_loss: 0.3438\n",
      "Epoch 168/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3319 - val_loss: 0.3430\n",
      "Epoch 169/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3311 - val_loss: 0.3423\n",
      "Epoch 170/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3301 - val_loss: 0.3409\n",
      "Epoch 171/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3292 - val_loss: 0.3401\n",
      "Epoch 172/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3283 - val_loss: 0.3390\n",
      "Epoch 173/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3275 - val_loss: 0.3384\n",
      "Epoch 174/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3265 - val_loss: 0.3375\n",
      "Epoch 175/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3257 - val_loss: 0.3363\n",
      "Epoch 176/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3247 - val_loss: 0.3355\n",
      "Epoch 177/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3238 - val_loss: 0.3344\n",
      "Epoch 178/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3229 - val_loss: 0.3338\n",
      "Epoch 179/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3222 - val_loss: 0.3331\n",
      "Epoch 180/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3212 - val_loss: 0.3317\n",
      "Epoch 181/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3204 - val_loss: 0.3308\n",
      "Epoch 182/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3193 - val_loss: 0.3300\n",
      "Epoch 183/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3185 - val_loss: 0.3291\n",
      "Epoch 184/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3176 - val_loss: 0.3283\n",
      "Epoch 185/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3166 - val_loss: 0.3273\n",
      "Epoch 186/2000\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.3159 - val_loss: 0.3264\n",
      "Epoch 187/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.3151 - val_loss: 0.3255\n",
      "Epoch 188/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3141 - val_loss: 0.3252\n",
      "Epoch 189/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3134 - val_loss: 0.3242\n",
      "Epoch 190/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3126 - val_loss: 0.3230\n",
      "Epoch 191/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3119 - val_loss: 0.3223\n",
      "Epoch 192/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3109 - val_loss: 0.3214\n",
      "Epoch 193/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3101 - val_loss: 0.3204\n",
      "Epoch 194/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3091 - val_loss: 0.3198\n",
      "Epoch 195/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3084 - val_loss: 0.3187\n",
      "Epoch 196/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.3076 - val_loss: 0.3182\n",
      "Epoch 197/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3068 - val_loss: 0.3170\n",
      "Epoch 198/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3061 - val_loss: 0.3161\n",
      "Epoch 199/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3053 - val_loss: 0.3155\n",
      "Epoch 200/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3045 - val_loss: 0.3147\n",
      "Epoch 201/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3037 - val_loss: 0.3139\n",
      "Epoch 202/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.3029 - val_loss: 0.3130\n",
      "Epoch 203/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3022 - val_loss: 0.3123\n",
      "Epoch 204/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.3013 - val_loss: 0.3114\n",
      "Epoch 205/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3005 - val_loss: 0.3109\n",
      "Epoch 206/2000\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.2999 - val_loss: 0.3104\n",
      "Epoch 207/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2992 - val_loss: 0.3092\n",
      "Epoch 208/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2982 - val_loss: 0.3088\n",
      "Epoch 209/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2976 - val_loss: 0.3078\n",
      "Epoch 210/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2971 - val_loss: 0.3073\n",
      "Epoch 211/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2964 - val_loss: 0.3063\n",
      "Epoch 212/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2957 - val_loss: 0.3055\n",
      "Epoch 213/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2949 - val_loss: 0.3048\n",
      "Epoch 214/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2941 - val_loss: 0.3041\n",
      "Epoch 215/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2934 - val_loss: 0.3033\n",
      "Epoch 216/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2927 - val_loss: 0.3026\n",
      "Epoch 217/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2922 - val_loss: 0.3021\n",
      "Epoch 218/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2914 - val_loss: 0.3015\n",
      "Epoch 219/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2907 - val_loss: 0.3006\n",
      "Epoch 220/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2900 - val_loss: 0.2999\n",
      "Epoch 221/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2897 - val_loss: 0.2994\n",
      "Epoch 222/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2887 - val_loss: 0.2985\n",
      "Epoch 223/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2881 - val_loss: 0.2978\n",
      "Epoch 224/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2875 - val_loss: 0.2974\n",
      "Epoch 225/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2869 - val_loss: 0.2966\n",
      "Epoch 226/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2863 - val_loss: 0.2960\n",
      "Epoch 227/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2857 - val_loss: 0.2955\n",
      "Epoch 228/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2851 - val_loss: 0.2951\n",
      "Epoch 229/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2847 - val_loss: 0.2946\n",
      "Epoch 230/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2842 - val_loss: 0.2939\n",
      "Epoch 231/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2835 - val_loss: 0.2928\n",
      "Epoch 232/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2829 - val_loss: 0.2923\n",
      "Epoch 233/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2824 - val_loss: 0.2918\n",
      "Epoch 234/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2818 - val_loss: 0.2918\n",
      "Epoch 235/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2814 - val_loss: 0.2909\n",
      "Epoch 236/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2807 - val_loss: 0.2905\n",
      "Epoch 237/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2802 - val_loss: 0.2896\n",
      "Epoch 238/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2798 - val_loss: 0.2889\n",
      "Epoch 239/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2792 - val_loss: 0.2885\n",
      "Epoch 240/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2786 - val_loss: 0.2884\n",
      "Epoch 241/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2782 - val_loss: 0.2876\n",
      "Epoch 242/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2777 - val_loss: 0.2870\n",
      "Epoch 243/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2774 - val_loss: 0.2867\n",
      "Epoch 244/2000\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.2767 - val_loss: 0.2861\n",
      "Epoch 245/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2764 - val_loss: 0.2858\n",
      "Epoch 246/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2759 - val_loss: 0.2852\n",
      "Epoch 247/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2754 - val_loss: 0.2845\n",
      "Epoch 248/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2750 - val_loss: 0.2842\n",
      "Epoch 249/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2745 - val_loss: 0.2838\n",
      "Epoch 250/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2741 - val_loss: 0.2834\n",
      "Epoch 251/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2737 - val_loss: 0.2828\n",
      "Epoch 252/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2733 - val_loss: 0.2824\n",
      "Epoch 253/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2728 - val_loss: 0.2820\n",
      "Epoch 254/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2724 - val_loss: 0.2816\n",
      "Epoch 255/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2719 - val_loss: 0.2810\n",
      "Epoch 256/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2715 - val_loss: 0.2808\n",
      "Epoch 257/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2712 - val_loss: 0.2804\n",
      "Epoch 258/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2707 - val_loss: 0.2798\n",
      "Epoch 259/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2705 - val_loss: 0.2796\n",
      "Epoch 260/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2702 - val_loss: 0.2794\n",
      "Epoch 261/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2697 - val_loss: 0.2789\n",
      "Epoch 262/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2693 - val_loss: 0.2787\n",
      "Epoch 263/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2690 - val_loss: 0.2781\n",
      "Epoch 264/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2686 - val_loss: 0.2774\n",
      "Epoch 265/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2682 - val_loss: 0.2776\n",
      "Epoch 266/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2680 - val_loss: 0.2770\n",
      "Epoch 267/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2677 - val_loss: 0.2765\n",
      "Epoch 268/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2673 - val_loss: 0.2761\n",
      "Epoch 269/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2670 - val_loss: 0.2757\n",
      "Epoch 270/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.2666 - val_loss: 0.2755\n",
      "Epoch 271/2000\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.2663 - val_loss: 0.2753\n",
      "Epoch 272/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2660 - val_loss: 0.2754\n",
      "Epoch 273/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2657 - val_loss: 0.2747\n",
      "Epoch 274/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2655 - val_loss: 0.2743\n",
      "Epoch 275/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2651 - val_loss: 0.2742\n",
      "Epoch 276/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2648 - val_loss: 0.2738\n",
      "Epoch 277/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2646 - val_loss: 0.2733\n",
      "Epoch 278/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2642 - val_loss: 0.2729\n",
      "Epoch 279/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2641 - val_loss: 0.2727\n",
      "Epoch 280/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2637 - val_loss: 0.2729\n",
      "Epoch 281/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2636 - val_loss: 0.2728\n",
      "Epoch 282/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2631 - val_loss: 0.2720\n",
      "Epoch 283/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2628 - val_loss: 0.2716\n",
      "Epoch 284/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2625 - val_loss: 0.2712\n",
      "Epoch 285/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2624 - val_loss: 0.2711\n",
      "Epoch 286/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2621 - val_loss: 0.2707\n",
      "Epoch 287/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2618 - val_loss: 0.2707\n",
      "Epoch 288/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2615 - val_loss: 0.2705\n",
      "Epoch 289/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2613 - val_loss: 0.2701\n",
      "Epoch 290/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2610 - val_loss: 0.2701\n",
      "Epoch 291/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2609 - val_loss: 0.2695\n",
      "Epoch 292/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2607 - val_loss: 0.2695\n",
      "Epoch 293/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2604 - val_loss: 0.2694\n",
      "Epoch 294/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2602 - val_loss: 0.2687\n",
      "Epoch 295/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2599 - val_loss: 0.2689\n",
      "Epoch 296/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2596 - val_loss: 0.2688\n",
      "Epoch 297/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2596 - val_loss: 0.2681\n",
      "Epoch 298/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2592 - val_loss: 0.2679\n",
      "Epoch 299/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2590 - val_loss: 0.2679\n",
      "Epoch 300/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2588 - val_loss: 0.2678\n",
      "Epoch 301/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2586 - val_loss: 0.2674\n",
      "Epoch 302/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2583 - val_loss: 0.2672\n",
      "Epoch 303/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2582 - val_loss: 0.2670\n",
      "Epoch 304/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2579 - val_loss: 0.2668\n",
      "Epoch 305/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2579 - val_loss: 0.2666\n",
      "Epoch 306/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2577 - val_loss: 0.2663\n",
      "Epoch 307/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2575 - val_loss: 0.2667\n",
      "Epoch 308/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2573 - val_loss: 0.2661\n",
      "Epoch 309/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2570 - val_loss: 0.2660\n",
      "Epoch 310/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2568 - val_loss: 0.2657\n",
      "Epoch 311/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2567 - val_loss: 0.2657\n",
      "Epoch 312/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2564 - val_loss: 0.2653\n",
      "Epoch 313/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2564 - val_loss: 0.2651\n",
      "Epoch 314/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2561 - val_loss: 0.2657\n",
      "Epoch 315/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2562 - val_loss: 0.2647\n",
      "Epoch 316/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2558 - val_loss: 0.2651\n",
      "Epoch 317/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2558 - val_loss: 0.2647\n",
      "Epoch 318/2000\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.2555 - val_loss: 0.2643\n",
      "Epoch 319/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2554 - val_loss: 0.2641\n",
      "Epoch 320/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.2552 - val_loss: 0.2641\n",
      "Epoch 321/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2553 - val_loss: 0.2638\n",
      "Epoch 322/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2550 - val_loss: 0.2637\n",
      "Epoch 323/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2546 - val_loss: 0.2635\n",
      "Epoch 324/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2547 - val_loss: 0.2644\n",
      "Epoch 325/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2545 - val_loss: 0.2631\n",
      "Epoch 326/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2543 - val_loss: 0.2633\n",
      "Epoch 327/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2541 - val_loss: 0.2631\n",
      "Epoch 328/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2539 - val_loss: 0.2629\n",
      "Epoch 329/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2537 - val_loss: 0.2630\n",
      "Epoch 330/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2537 - val_loss: 0.2629\n",
      "Epoch 331/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2536 - val_loss: 0.2630\n",
      "Epoch 332/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2536 - val_loss: 0.2626\n",
      "Epoch 333/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2532 - val_loss: 0.2622\n",
      "Epoch 334/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2531 - val_loss: 0.2624\n",
      "Epoch 335/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2531 - val_loss: 0.2621\n",
      "Epoch 336/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2529 - val_loss: 0.2619\n",
      "Epoch 337/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2528 - val_loss: 0.2620\n",
      "Epoch 338/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2527 - val_loss: 0.2621\n",
      "Epoch 339/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2525 - val_loss: 0.2613\n",
      "Epoch 340/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2524 - val_loss: 0.2620\n",
      "Epoch 341/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2524 - val_loss: 0.2615\n",
      "Epoch 342/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2522 - val_loss: 0.2609\n",
      "Epoch 343/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2520 - val_loss: 0.2612\n",
      "Epoch 344/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2519 - val_loss: 0.2609\n",
      "Epoch 345/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2517 - val_loss: 0.2618\n",
      "Epoch 346/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2518 - val_loss: 0.2615\n",
      "Epoch 347/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2516 - val_loss: 0.2608\n",
      "Epoch 348/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2515 - val_loss: 0.2603\n",
      "Epoch 349/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2512 - val_loss: 0.2602\n",
      "Epoch 350/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2511 - val_loss: 0.2612\n",
      "Epoch 351/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2511 - val_loss: 0.2601\n",
      "Epoch 352/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2512 - val_loss: 0.2604\n",
      "Epoch 353/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2510 - val_loss: 0.2600\n",
      "Epoch 354/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2507 - val_loss: 0.2599\n",
      "Epoch 355/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2507 - val_loss: 0.2598\n",
      "Epoch 356/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2506 - val_loss: 0.2599\n",
      "Epoch 357/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2505 - val_loss: 0.2597\n",
      "Epoch 358/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2505 - val_loss: 0.2602\n",
      "Epoch 359/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2504 - val_loss: 0.2596\n",
      "Epoch 360/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2502 - val_loss: 0.2591\n",
      "Epoch 361/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2502 - val_loss: 0.2591\n",
      "Epoch 362/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2500 - val_loss: 0.2595\n",
      "Epoch 363/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2501 - val_loss: 0.2592\n",
      "Epoch 364/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2497 - val_loss: 0.2589\n",
      "Epoch 365/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2497 - val_loss: 0.2593\n",
      "Epoch 366/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2496 - val_loss: 0.2587\n",
      "Epoch 367/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2494 - val_loss: 0.2589\n",
      "Epoch 368/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2495 - val_loss: 0.2586\n",
      "Epoch 369/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2492 - val_loss: 0.2584\n",
      "Epoch 370/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2492 - val_loss: 0.2590\n",
      "Epoch 371/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2491 - val_loss: 0.2582\n",
      "Epoch 372/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2491 - val_loss: 0.2584\n",
      "Epoch 373/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2491 - val_loss: 0.2586\n",
      "Epoch 374/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2490 - val_loss: 0.2582\n",
      "Epoch 375/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2489 - val_loss: 0.2578\n",
      "Epoch 376/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2487 - val_loss: 0.2580\n",
      "Epoch 377/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2486 - val_loss: 0.2581\n",
      "Epoch 378/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2484 - val_loss: 0.2579\n",
      "Epoch 379/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.2483 - val_loss: 0.2578\n",
      "Epoch 380/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2483 - val_loss: 0.2586\n",
      "Epoch 381/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2483 - val_loss: 0.2575\n",
      "Epoch 382/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2482 - val_loss: 0.2576\n",
      "Epoch 383/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2481 - val_loss: 0.2576\n",
      "Epoch 384/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2479 - val_loss: 0.2573\n",
      "Epoch 385/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2479 - val_loss: 0.2573\n",
      "Epoch 386/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2478 - val_loss: 0.2574\n",
      "Epoch 387/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2480 - val_loss: 0.2577\n",
      "Epoch 388/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2477 - val_loss: 0.2568\n",
      "Epoch 389/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2477 - val_loss: 0.2571\n",
      "Epoch 390/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2478 - val_loss: 0.2569\n",
      "Epoch 391/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2476 - val_loss: 0.2569\n",
      "Epoch 392/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2474 - val_loss: 0.2568\n",
      "Epoch 393/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2473 - val_loss: 0.2567\n",
      "Epoch 394/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2473 - val_loss: 0.2570\n",
      "Epoch 395/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2471 - val_loss: 0.2565\n",
      "Epoch 396/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2471 - val_loss: 0.2565\n",
      "Epoch 397/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2470 - val_loss: 0.2566\n",
      "Epoch 398/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2469 - val_loss: 0.2568\n",
      "Epoch 399/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2469 - val_loss: 0.2566\n",
      "Epoch 400/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2469 - val_loss: 0.2563\n",
      "Epoch 401/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2467 - val_loss: 0.2564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2466 - val_loss: 0.2568\n",
      "Epoch 403/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2466 - val_loss: 0.2561\n",
      "Epoch 404/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2466 - val_loss: 0.2564\n",
      "Epoch 405/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2468 - val_loss: 0.2562\n",
      "Epoch 406/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2464 - val_loss: 0.2563\n",
      "Epoch 407/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2463 - val_loss: 0.2559\n",
      "Epoch 408/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2465 - val_loss: 0.2564\n",
      "Epoch 409/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2462 - val_loss: 0.2561\n",
      "Epoch 410/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2461 - val_loss: 0.2562\n",
      "Epoch 411/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2460 - val_loss: 0.2554\n",
      "Epoch 412/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2463 - val_loss: 0.2561\n",
      "Epoch 413/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2460 - val_loss: 0.2555\n",
      "Epoch 414/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2460 - val_loss: 0.2562\n",
      "Epoch 415/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2458 - val_loss: 0.2557\n",
      "Epoch 416/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2458 - val_loss: 0.2556\n",
      "Epoch 417/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2456 - val_loss: 0.2554\n",
      "Epoch 418/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2456 - val_loss: 0.2553\n",
      "Epoch 419/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2458 - val_loss: 0.2552\n",
      "Epoch 420/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2454 - val_loss: 0.2554\n",
      "Epoch 421/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2453 - val_loss: 0.2554\n",
      "Epoch 422/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2453 - val_loss: 0.2551\n",
      "Epoch 423/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2452 - val_loss: 0.2555\n",
      "Epoch 424/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2453 - val_loss: 0.2553\n",
      "Epoch 425/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2452 - val_loss: 0.2551\n",
      "Epoch 426/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2451 - val_loss: 0.2551\n",
      "Epoch 427/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2450 - val_loss: 0.2546\n",
      "Epoch 428/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2450 - val_loss: 0.2548\n",
      "Epoch 429/2000\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.2449 - val_loss: 0.2552\n",
      "Epoch 430/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2448 - val_loss: 0.2546\n",
      "Epoch 431/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2448 - val_loss: 0.2547\n",
      "Epoch 432/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.2447 - val_loss: 0.2550\n",
      "Epoch 433/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2446 - val_loss: 0.2548\n",
      "Epoch 434/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2445 - val_loss: 0.2547\n",
      "Epoch 435/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2446 - val_loss: 0.2546\n",
      "Epoch 436/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2444 - val_loss: 0.2547\n",
      "Epoch 437/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2444 - val_loss: 0.2543\n",
      "Epoch 438/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2442 - val_loss: 0.2541\n",
      "Epoch 439/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2445 - val_loss: 0.2547\n",
      "Epoch 440/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2443 - val_loss: 0.2538\n",
      "Epoch 441/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2442 - val_loss: 0.2540\n",
      "Epoch 442/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2442 - val_loss: 0.2540\n",
      "Epoch 443/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2442 - val_loss: 0.2543\n",
      "Epoch 444/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2442 - val_loss: 0.2541\n",
      "Epoch 445/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.2538\n",
      "Epoch 446/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2439 - val_loss: 0.2538\n",
      "Epoch 447/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2439 - val_loss: 0.2541\n",
      "Epoch 448/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2438 - val_loss: 0.2538\n",
      "Epoch 449/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2438 - val_loss: 0.2539\n",
      "Epoch 450/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2437 - val_loss: 0.2537\n",
      "Epoch 451/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2436 - val_loss: 0.2537\n",
      "Epoch 452/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2436 - val_loss: 0.2543\n",
      "Epoch 453/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2436 - val_loss: 0.2534\n",
      "Epoch 454/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2436 - val_loss: 0.2538\n",
      "Epoch 455/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2435 - val_loss: 0.2536\n",
      "Epoch 456/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2436 - val_loss: 0.2535\n",
      "Epoch 457/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2434 - val_loss: 0.2533\n",
      "Epoch 458/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2434 - val_loss: 0.2536\n",
      "Epoch 459/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2434 - val_loss: 0.2531\n",
      "Epoch 460/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2432 - val_loss: 0.2533\n",
      "Epoch 461/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2431 - val_loss: 0.2536\n",
      "Epoch 462/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2431 - val_loss: 0.2533\n",
      "Epoch 463/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2432 - val_loss: 0.2531\n",
      "Epoch 464/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2430 - val_loss: 0.2530\n",
      "Epoch 465/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2429 - val_loss: 0.2530\n",
      "Epoch 466/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2430 - val_loss: 0.2528\n",
      "Epoch 467/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2429 - val_loss: 0.2532\n",
      "Epoch 468/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2429 - val_loss: 0.2537\n",
      "Epoch 469/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2429 - val_loss: 0.2534\n",
      "Epoch 470/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2427 - val_loss: 0.2529\n",
      "Epoch 471/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2427 - val_loss: 0.2528\n",
      "Epoch 472/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2426 - val_loss: 0.2530\n",
      "Epoch 473/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2426 - val_loss: 0.2527\n",
      "Epoch 474/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2427 - val_loss: 0.2531\n",
      "Epoch 475/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2426 - val_loss: 0.2524\n",
      "Epoch 476/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2427 - val_loss: 0.2526\n",
      "Epoch 477/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2425 - val_loss: 0.2529\n",
      "Epoch 478/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2428 - val_loss: 0.2526\n",
      "Epoch 479/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2423 - val_loss: 0.2532\n",
      "Epoch 480/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2424 - val_loss: 0.2524\n",
      "Epoch 481/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2424 - val_loss: 0.2522\n",
      "Epoch 482/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2422 - val_loss: 0.2528\n",
      "Epoch 483/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2422 - val_loss: 0.2524\n",
      "Epoch 484/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2421 - val_loss: 0.2523\n",
      "Epoch 485/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2420 - val_loss: 0.2523\n",
      "Epoch 486/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2420 - val_loss: 0.2523\n",
      "Epoch 487/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2421 - val_loss: 0.2522\n",
      "Epoch 488/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2420 - val_loss: 0.2523\n",
      "Epoch 489/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2419 - val_loss: 0.2522\n",
      "Epoch 490/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2418 - val_loss: 0.2519\n",
      "Epoch 491/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2419 - val_loss: 0.2518\n",
      "Epoch 492/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2418 - val_loss: 0.2519\n",
      "Epoch 493/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2418 - val_loss: 0.2520\n",
      "Epoch 494/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2418 - val_loss: 0.2520\n",
      "Epoch 495/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2416 - val_loss: 0.2517\n",
      "Epoch 496/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2416 - val_loss: 0.2522\n",
      "Epoch 497/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2415 - val_loss: 0.2519\n",
      "Epoch 498/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2416 - val_loss: 0.2519\n",
      "Epoch 499/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2416 - val_loss: 0.2520\n",
      "Epoch 500/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2415 - val_loss: 0.2516\n",
      "Epoch 501/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2414 - val_loss: 0.2518\n",
      "Epoch 502/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2414 - val_loss: 0.2520\n",
      "Epoch 503/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2413 - val_loss: 0.2517\n",
      "Epoch 504/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2413 - val_loss: 0.2514\n",
      "Epoch 505/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2413 - val_loss: 0.2518\n",
      "Epoch 506/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2412 - val_loss: 0.2523\n",
      "Epoch 507/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2412 - val_loss: 0.2515\n",
      "Epoch 508/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2410 - val_loss: 0.2515\n",
      "Epoch 509/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2411 - val_loss: 0.2517\n",
      "Epoch 510/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2410 - val_loss: 0.2513\n",
      "Epoch 511/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2409 - val_loss: 0.2511\n",
      "Epoch 512/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2410 - val_loss: 0.2516\n",
      "Epoch 513/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2409 - val_loss: 0.2516\n",
      "Epoch 514/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2409 - val_loss: 0.2513\n",
      "Epoch 515/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2409 - val_loss: 0.2514\n",
      "Epoch 516/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2408 - val_loss: 0.2513\n",
      "Epoch 517/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2408 - val_loss: 0.2513\n",
      "Epoch 518/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2407 - val_loss: 0.2511\n",
      "Epoch 519/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2408 - val_loss: 0.2511\n",
      "Epoch 520/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2406 - val_loss: 0.2514\n",
      "Epoch 521/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2405 - val_loss: 0.2510\n",
      "Epoch 522/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2405 - val_loss: 0.2515\n",
      "Epoch 523/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2406 - val_loss: 0.2518\n",
      "Epoch 524/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2407 - val_loss: 0.2510\n",
      "Epoch 525/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2405 - val_loss: 0.2509\n",
      "Epoch 526/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2404 - val_loss: 0.2508\n",
      "Epoch 527/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2406 - val_loss: 0.2509\n",
      "Epoch 528/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2403 - val_loss: 0.2509\n",
      "Epoch 529/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2402 - val_loss: 0.2507\n",
      "Epoch 530/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2403 - val_loss: 0.2510\n",
      "Epoch 531/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2407 - val_loss: 0.2509\n",
      "Epoch 532/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2401 - val_loss: 0.2513\n",
      "Epoch 533/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2402 - val_loss: 0.2506\n",
      "Epoch 534/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2401 - val_loss: 0.2510\n",
      "Epoch 535/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2402 - val_loss: 0.2506\n",
      "Epoch 536/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2400 - val_loss: 0.2512\n",
      "Epoch 537/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2400 - val_loss: 0.2508\n",
      "Epoch 538/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2400 - val_loss: 0.2507\n",
      "Epoch 539/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2400 - val_loss: 0.2508\n",
      "Epoch 540/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2400 - val_loss: 0.2505\n",
      "Epoch 541/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2399 - val_loss: 0.2506\n",
      "Epoch 542/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2399 - val_loss: 0.2504\n",
      "Epoch 543/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2398 - val_loss: 0.2506\n",
      "Epoch 544/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2398 - val_loss: 0.2502\n",
      "Epoch 545/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2397 - val_loss: 0.2504\n",
      "Epoch 546/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2397 - val_loss: 0.2502\n",
      "Epoch 547/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2399 - val_loss: 0.2508\n",
      "Epoch 548/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2399 - val_loss: 0.2503\n",
      "Epoch 549/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2396 - val_loss: 0.2504\n",
      "Epoch 550/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2396 - val_loss: 0.2509\n",
      "Epoch 551/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2396 - val_loss: 0.2501\n",
      "Epoch 552/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2396 - val_loss: 0.2503\n",
      "Epoch 553/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2394 - val_loss: 0.2504\n",
      "Epoch 554/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2395 - val_loss: 0.2501\n",
      "Epoch 555/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2396 - val_loss: 0.2504\n",
      "Epoch 556/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2393 - val_loss: 0.2504\n",
      "Epoch 557/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2394 - val_loss: 0.2499\n",
      "Epoch 558/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2395 - val_loss: 0.2501\n",
      "Epoch 559/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2393 - val_loss: 0.2501\n",
      "Epoch 560/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2392 - val_loss: 0.2498\n",
      "Epoch 561/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2392 - val_loss: 0.2499\n",
      "Epoch 562/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2392 - val_loss: 0.2501\n",
      "Epoch 563/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2391 - val_loss: 0.2499\n",
      "Epoch 564/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2391 - val_loss: 0.2499\n",
      "Epoch 565/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.2497\n",
      "Epoch 566/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2391 - val_loss: 0.2502\n",
      "Epoch 567/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.2498\n",
      "Epoch 568/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.2499\n",
      "Epoch 569/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.2498\n",
      "Epoch 570/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.2505\n",
      "Epoch 571/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.2499\n",
      "Epoch 572/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2389 - val_loss: 0.2496\n",
      "Epoch 573/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2388 - val_loss: 0.2500\n",
      "Epoch 574/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.2496\n",
      "Epoch 575/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2389 - val_loss: 0.2496\n",
      "Epoch 576/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2389 - val_loss: 0.2497\n",
      "Epoch 577/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2387 - val_loss: 0.2499\n",
      "Epoch 578/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2386 - val_loss: 0.2497\n",
      "Epoch 579/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2387 - val_loss: 0.2496\n",
      "Epoch 580/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2386 - val_loss: 0.2495\n",
      "Epoch 581/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2386 - val_loss: 0.2493\n",
      "Epoch 582/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2386 - val_loss: 0.2494\n",
      "Epoch 583/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2387 - val_loss: 0.2497\n",
      "Epoch 584/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.2501\n",
      "Epoch 585/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2386 - val_loss: 0.2495\n",
      "Epoch 586/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.2494\n",
      "Epoch 587/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2384 - val_loss: 0.2498\n",
      "Epoch 588/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2384 - val_loss: 0.2493\n",
      "Epoch 589/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2383 - val_loss: 0.2496\n",
      "Epoch 590/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2384 - val_loss: 0.2495\n",
      "Epoch 591/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2382 - val_loss: 0.2494\n",
      "Epoch 592/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2384 - val_loss: 0.2490\n",
      "Epoch 593/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2383 - val_loss: 0.2491\n",
      "Epoch 594/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2382 - val_loss: 0.2492\n",
      "Epoch 595/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2383 - val_loss: 0.2491\n",
      "Epoch 596/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2382 - val_loss: 0.2496\n",
      "Epoch 597/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2383 - val_loss: 0.2490\n",
      "Epoch 598/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2380 - val_loss: 0.2492\n",
      "Epoch 599/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2381 - val_loss: 0.2491\n",
      "Epoch 600/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2381 - val_loss: 0.2488\n",
      "Epoch 601/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2382 - val_loss: 0.2493\n",
      "Epoch 602/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2381 - val_loss: 0.2489\n",
      "Epoch 603/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2381 - val_loss: 0.2488\n",
      "Epoch 604/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2381 - val_loss: 0.2488\n",
      "Epoch 605/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2379 - val_loss: 0.2493\n",
      "Epoch 606/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2380 - val_loss: 0.2493\n",
      "Epoch 607/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2380 - val_loss: 0.2490\n",
      "Epoch 608/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2378 - val_loss: 0.2489\n",
      "Epoch 609/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2378 - val_loss: 0.2488\n",
      "Epoch 610/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2377 - val_loss: 0.2493\n",
      "Epoch 611/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2380 - val_loss: 0.2491\n",
      "Epoch 612/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2378 - val_loss: 0.2486\n",
      "Epoch 613/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2377 - val_loss: 0.2495\n",
      "Epoch 614/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2376 - val_loss: 0.2485\n",
      "Epoch 615/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2377 - val_loss: 0.2488\n",
      "Epoch 616/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2376 - val_loss: 0.2487\n",
      "Epoch 617/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2376 - val_loss: 0.2486\n",
      "Epoch 618/2000\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.2377 - val_loss: 0.2487\n",
      "Epoch 619/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2376 - val_loss: 0.2491\n",
      "Epoch 620/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2376 - val_loss: 0.2487\n",
      "Epoch 621/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2375 - val_loss: 0.2486\n",
      "Epoch 622/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2377 - val_loss: 0.2485\n",
      "Epoch 623/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2373 - val_loss: 0.2490\n",
      "Epoch 624/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2375 - val_loss: 0.2484\n",
      "Epoch 625/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2375 - val_loss: 0.2488\n",
      "Epoch 626/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2373 - val_loss: 0.2488\n",
      "Epoch 627/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2375 - val_loss: 0.2490\n",
      "Epoch 628/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2373 - val_loss: 0.2485\n",
      "Epoch 629/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2373 - val_loss: 0.2484\n",
      "Epoch 630/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2373 - val_loss: 0.2484\n",
      "Epoch 631/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2373 - val_loss: 0.2485\n",
      "Epoch 632/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2373 - val_loss: 0.2483\n",
      "Epoch 633/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2372 - val_loss: 0.2484\n",
      "Epoch 634/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.2371 - val_loss: 0.2484\n",
      "Epoch 635/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2370 - val_loss: 0.2483\n",
      "Epoch 636/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2370 - val_loss: 0.2490\n",
      "Epoch 637/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2371 - val_loss: 0.2483\n",
      "Epoch 638/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2371 - val_loss: 0.2485\n",
      "Epoch 639/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2370 - val_loss: 0.2483\n",
      "Epoch 640/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2372 - val_loss: 0.2484\n",
      "Epoch 641/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2369 - val_loss: 0.2484\n",
      "Epoch 642/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2370 - val_loss: 0.2483\n",
      "Epoch 643/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2369 - val_loss: 0.2486\n",
      "Epoch 644/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2369 - val_loss: 0.2484\n",
      "Epoch 645/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2370 - val_loss: 0.2481\n",
      "Epoch 646/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2369 - val_loss: 0.2481\n",
      "Epoch 647/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2368 - val_loss: 0.2484\n",
      "Epoch 648/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2367 - val_loss: 0.2481\n",
      "Epoch 649/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2369 - val_loss: 0.2482\n",
      "Epoch 650/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2367 - val_loss: 0.2480\n",
      "Epoch 651/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2368 - val_loss: 0.2480\n",
      "Epoch 652/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2368 - val_loss: 0.2489\n",
      "Epoch 653/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2367 - val_loss: 0.2479\n",
      "Epoch 654/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2369 - val_loss: 0.2482\n",
      "Epoch 655/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2365 - val_loss: 0.2485\n",
      "Epoch 656/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2366 - val_loss: 0.2480\n",
      "Epoch 657/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2366 - val_loss: 0.2480\n",
      "Epoch 658/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2365 - val_loss: 0.2486\n",
      "Epoch 659/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2365 - val_loss: 0.2477\n",
      "Epoch 660/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2364 - val_loss: 0.2481\n",
      "Epoch 661/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2364 - val_loss: 0.2482\n",
      "Epoch 662/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2365 - val_loss: 0.2476\n",
      "Epoch 663/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2364 - val_loss: 0.2486\n",
      "Epoch 664/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2364 - val_loss: 0.2479\n",
      "Epoch 665/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2364 - val_loss: 0.2478\n",
      "Epoch 666/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2364 - val_loss: 0.2481\n",
      "Epoch 667/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2363 - val_loss: 0.2478\n",
      "Epoch 668/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2363 - val_loss: 0.2485\n",
      "Epoch 669/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2363 - val_loss: 0.2475\n",
      "Epoch 670/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2362 - val_loss: 0.2478\n",
      "Epoch 671/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2361 - val_loss: 0.2477\n",
      "Epoch 672/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2362 - val_loss: 0.2477\n",
      "Epoch 673/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2362 - val_loss: 0.2474\n",
      "Epoch 674/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2361 - val_loss: 0.2481\n",
      "Epoch 675/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2361 - val_loss: 0.2476\n",
      "Epoch 676/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2361 - val_loss: 0.2476\n",
      "Epoch 677/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2362 - val_loss: 0.2476\n",
      "Epoch 678/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2362 - val_loss: 0.2476\n",
      "Epoch 679/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2360 - val_loss: 0.2476\n",
      "Epoch 680/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2360 - val_loss: 0.2475\n",
      "Epoch 681/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2361 - val_loss: 0.2474\n",
      "Epoch 682/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2362 - val_loss: 0.2476\n",
      "Epoch 683/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2360 - val_loss: 0.2476\n",
      "Epoch 684/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2359 - val_loss: 0.2477\n",
      "Epoch 685/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2360 - val_loss: 0.2475\n",
      "Epoch 686/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2359 - val_loss: 0.2474\n",
      "Epoch 687/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2359 - val_loss: 0.2472\n",
      "Epoch 688/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2359 - val_loss: 0.2476\n",
      "Epoch 689/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2358 - val_loss: 0.2473\n",
      "Epoch 690/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2360 - val_loss: 0.2476\n",
      "Epoch 691/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2358 - val_loss: 0.2474\n",
      "Epoch 692/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2358 - val_loss: 0.2475\n",
      "Epoch 693/2000\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.2358 - val_loss: 0.2476\n",
      "Epoch 694/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2356 - val_loss: 0.2474\n",
      "Epoch 695/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2356 - val_loss: 0.2473\n",
      "Epoch 696/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2357 - val_loss: 0.2473\n",
      "Epoch 697/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2355 - val_loss: 0.2473\n",
      "Epoch 698/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2356 - val_loss: 0.2472\n",
      "Epoch 699/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2356 - val_loss: 0.2476\n",
      "Epoch 700/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2356 - val_loss: 0.2469\n",
      "Epoch 701/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2354 - val_loss: 0.2474\n",
      "Epoch 702/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2355 - val_loss: 0.2470\n",
      "Epoch 703/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2355 - val_loss: 0.2472\n",
      "Epoch 704/2000\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.2357 - val_loss: 0.2472\n",
      "Epoch 705/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2354 - val_loss: 0.2470\n",
      "Epoch 706/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2356 - val_loss: 0.2482\n",
      "Epoch 707/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2355 - val_loss: 0.2472\n",
      "Epoch 708/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2355 - val_loss: 0.2471\n",
      "Epoch 709/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2355 - val_loss: 0.2471\n",
      "Epoch 710/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2354 - val_loss: 0.2469\n",
      "Epoch 711/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2353 - val_loss: 0.2477\n",
      "Epoch 712/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2354 - val_loss: 0.2470\n",
      "Epoch 713/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2352 - val_loss: 0.2471\n",
      "Epoch 714/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2354 - val_loss: 0.2473\n",
      "Epoch 715/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2353 - val_loss: 0.2469\n",
      "Epoch 716/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2352 - val_loss: 0.2469\n",
      "Epoch 717/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2351 - val_loss: 0.2471\n",
      "Epoch 718/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2353 - val_loss: 0.2475\n",
      "Epoch 719/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2352 - val_loss: 0.2470\n",
      "Epoch 720/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2352 - val_loss: 0.2469\n",
      "Epoch 721/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2354 - val_loss: 0.2471\n",
      "Epoch 722/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2352 - val_loss: 0.2467\n",
      "Epoch 723/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2351 - val_loss: 0.2475\n",
      "Epoch 724/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2351 - val_loss: 0.2468\n",
      "Epoch 725/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2350 - val_loss: 0.2472\n",
      "Epoch 726/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2350 - val_loss: 0.2466\n",
      "Epoch 727/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2351 - val_loss: 0.2467\n",
      "Epoch 728/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2350 - val_loss: 0.2469\n",
      "Epoch 729/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2350 - val_loss: 0.2471\n",
      "Epoch 730/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2350 - val_loss: 0.2465\n",
      "Epoch 731/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2350 - val_loss: 0.2471\n",
      "Epoch 732/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2349 - val_loss: 0.2466\n",
      "Epoch 733/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2350 - val_loss: 0.2475\n",
      "Epoch 734/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2352 - val_loss: 0.2470\n",
      "Epoch 735/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2350 - val_loss: 0.2469\n",
      "Epoch 736/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2349 - val_loss: 0.2465\n",
      "Epoch 737/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2348 - val_loss: 0.2468\n",
      "Epoch 738/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2348 - val_loss: 0.2468\n",
      "Epoch 739/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2348 - val_loss: 0.2469\n",
      "Epoch 740/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2349 - val_loss: 0.2467\n",
      "Epoch 741/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2346 - val_loss: 0.2467\n",
      "Epoch 742/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2347 - val_loss: 0.2467\n",
      "Epoch 743/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2347 - val_loss: 0.2466\n",
      "Epoch 744/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2346 - val_loss: 0.2465\n",
      "Epoch 745/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2346 - val_loss: 0.2468\n",
      "Epoch 746/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2347 - val_loss: 0.2468\n",
      "Epoch 747/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2346 - val_loss: 0.2469\n",
      "Epoch 748/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2347 - val_loss: 0.2473\n",
      "Epoch 749/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2348 - val_loss: 0.2464\n",
      "Epoch 750/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2348 - val_loss: 0.2466\n",
      "Epoch 751/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2347 - val_loss: 0.2466\n",
      "Epoch 752/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2345 - val_loss: 0.2471\n",
      "Epoch 753/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2346 - val_loss: 0.2467\n",
      "Epoch 754/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2344 - val_loss: 0.2464\n",
      "Epoch 755/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2344 - val_loss: 0.2463\n",
      "Epoch 756/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2345 - val_loss: 0.2465\n",
      "Epoch 757/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2344 - val_loss: 0.2466\n",
      "Epoch 758/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2344 - val_loss: 0.2466\n",
      "Epoch 759/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2345 - val_loss: 0.2465\n",
      "Epoch 760/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2344 - val_loss: 0.2467\n",
      "Epoch 761/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2344 - val_loss: 0.2461\n",
      "Epoch 762/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2344 - val_loss: 0.2465\n",
      "Epoch 763/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2343 - val_loss: 0.2463\n",
      "Epoch 764/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2343 - val_loss: 0.2467\n",
      "Epoch 765/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2343 - val_loss: 0.2466\n",
      "Epoch 766/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2342 - val_loss: 0.2460\n",
      "Epoch 767/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2343 - val_loss: 0.2469\n",
      "Epoch 768/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2344 - val_loss: 0.2462\n",
      "Epoch 769/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2344 - val_loss: 0.2463\n",
      "Epoch 770/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2344 - val_loss: 0.2465\n",
      "Epoch 771/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2343 - val_loss: 0.2462\n",
      "Epoch 772/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2341 - val_loss: 0.2463\n",
      "Epoch 773/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2341 - val_loss: 0.2467\n",
      "Epoch 774/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2341 - val_loss: 0.2466\n",
      "Epoch 775/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2341 - val_loss: 0.2459\n",
      "Epoch 776/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2340 - val_loss: 0.2462\n",
      "Epoch 777/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2342 - val_loss: 0.2470\n",
      "Epoch 778/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2341 - val_loss: 0.2460\n",
      "Epoch 779/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2340 - val_loss: 0.2461\n",
      "Epoch 780/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2340 - val_loss: 0.2469\n",
      "Epoch 781/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2344 - val_loss: 0.2463\n",
      "Epoch 782/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2340 - val_loss: 0.2463\n",
      "Epoch 783/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2340 - val_loss: 0.2461\n",
      "Epoch 784/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2342 - val_loss: 0.2470\n",
      "Epoch 785/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2340 - val_loss: 0.2462\n",
      "Epoch 786/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2340 - val_loss: 0.2462\n",
      "Epoch 787/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2339 - val_loss: 0.2463\n",
      "Epoch 788/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2339 - val_loss: 0.2458\n",
      "Epoch 789/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2339 - val_loss: 0.2459\n",
      "Epoch 790/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2342 - val_loss: 0.2466\n",
      "Epoch 791/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2340 - val_loss: 0.2461\n",
      "Epoch 792/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2339 - val_loss: 0.2465\n",
      "Epoch 793/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2337 - val_loss: 0.2460\n",
      "Epoch 794/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2338 - val_loss: 0.2458\n",
      "Epoch 795/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2337 - val_loss: 0.2459\n",
      "Epoch 796/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2338 - val_loss: 0.2464\n",
      "Epoch 797/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2337 - val_loss: 0.2458\n",
      "Epoch 798/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2339 - val_loss: 0.2459\n",
      "Epoch 799/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2338 - val_loss: 0.2458\n",
      "Epoch 800/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2337 - val_loss: 0.2458\n",
      "Epoch 801/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2338 - val_loss: 0.2461\n",
      "Epoch 802/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2337 - val_loss: 0.2461\n",
      "Epoch 803/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2336 - val_loss: 0.2458\n",
      "Epoch 804/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2337 - val_loss: 0.2460\n",
      "Epoch 805/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2336 - val_loss: 0.2461\n",
      "Epoch 806/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2339 - val_loss: 0.2464\n",
      "Epoch 807/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2337 - val_loss: 0.2460\n",
      "Epoch 808/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2336 - val_loss: 0.2460\n",
      "Epoch 809/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2335 - val_loss: 0.2460\n",
      "Epoch 810/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2336 - val_loss: 0.2462\n",
      "Epoch 811/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2337 - val_loss: 0.2457\n",
      "Epoch 812/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2336 - val_loss: 0.2466\n",
      "Epoch 813/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2335 - val_loss: 0.2458\n",
      "Epoch 814/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2336 - val_loss: 0.2461\n",
      "Epoch 815/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2335 - val_loss: 0.2461\n",
      "Epoch 816/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2337 - val_loss: 0.2458\n",
      "Epoch 817/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2335 - val_loss: 0.2462\n",
      "Epoch 818/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2334 - val_loss: 0.2458\n",
      "Epoch 819/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2334 - val_loss: 0.2461\n",
      "Epoch 820/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2334 - val_loss: 0.2457\n",
      "Epoch 821/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2333 - val_loss: 0.2460\n",
      "Epoch 822/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2333 - val_loss: 0.2456\n",
      "Epoch 823/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2333 - val_loss: 0.2456\n",
      "Epoch 824/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2334 - val_loss: 0.2462\n",
      "Epoch 825/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2337 - val_loss: 0.2464\n",
      "Epoch 826/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2334 - val_loss: 0.2460\n",
      "Epoch 827/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2333 - val_loss: 0.2454\n",
      "Epoch 828/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2334 - val_loss: 0.2462\n",
      "Epoch 829/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2334 - val_loss: 0.2458\n",
      "Epoch 830/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2334 - val_loss: 0.2456\n",
      "Epoch 831/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2332 - val_loss: 0.2458\n",
      "Epoch 832/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2332 - val_loss: 0.2456\n",
      "Epoch 833/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2332 - val_loss: 0.2453\n",
      "Epoch 834/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2331 - val_loss: 0.2463\n",
      "Epoch 835/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2333 - val_loss: 0.2460\n",
      "Epoch 836/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2336 - val_loss: 0.2460\n",
      "Epoch 837/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2332 - val_loss: 0.2455\n",
      "Epoch 838/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2331 - val_loss: 0.2456\n",
      "Epoch 839/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2330 - val_loss: 0.2461\n",
      "Epoch 840/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2332 - val_loss: 0.2456\n",
      "Epoch 841/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2332 - val_loss: 0.2457\n",
      "Epoch 842/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2333 - val_loss: 0.2458\n",
      "Epoch 843/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2330 - val_loss: 0.2454\n",
      "Epoch 844/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2330 - val_loss: 0.2457\n",
      "Epoch 845/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2331 - val_loss: 0.2455\n",
      "Epoch 846/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2332 - val_loss: 0.2461\n",
      "Epoch 847/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2331 - val_loss: 0.2458\n",
      "Epoch 848/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2330 - val_loss: 0.2453\n",
      "Epoch 849/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2330 - val_loss: 0.2456\n",
      "Epoch 850/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2330 - val_loss: 0.2456\n",
      "Epoch 851/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2329 - val_loss: 0.2457\n",
      "Epoch 852/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2332 - val_loss: 0.2458\n",
      "Epoch 853/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2329 - val_loss: 0.2452\n",
      "Epoch 854/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2331 - val_loss: 0.2455\n",
      "Epoch 855/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2328 - val_loss: 0.2455\n",
      "Epoch 856/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2329 - val_loss: 0.2451\n",
      "Epoch 857/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2328 - val_loss: 0.2455\n",
      "Epoch 858/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2329 - val_loss: 0.2454\n",
      "Epoch 859/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2330 - val_loss: 0.2454\n",
      "Epoch 860/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2328 - val_loss: 0.2458\n",
      "Epoch 861/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2331 - val_loss: 0.2454\n",
      "Epoch 862/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2328 - val_loss: 0.2458\n",
      "Epoch 863/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2329 - val_loss: 0.2459\n",
      "Epoch 864/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2328 - val_loss: 0.2457\n",
      "Epoch 865/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2329 - val_loss: 0.2454\n",
      "Epoch 866/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2329 - val_loss: 0.2452\n",
      "Epoch 867/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2328 - val_loss: 0.2453\n",
      "Epoch 868/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2327 - val_loss: 0.2455\n",
      "Epoch 869/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2328 - val_loss: 0.2454\n",
      "Epoch 870/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2326 - val_loss: 0.2452\n",
      "Epoch 871/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2326 - val_loss: 0.2457\n",
      "Epoch 872/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2326 - val_loss: 0.2455\n",
      "Epoch 873/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2326 - val_loss: 0.2455\n",
      "Epoch 874/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2326 - val_loss: 0.2453\n",
      "Epoch 875/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2327 - val_loss: 0.2452\n",
      "Epoch 876/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2325 - val_loss: 0.2451\n",
      "Epoch 877/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2326 - val_loss: 0.2452\n",
      "Epoch 878/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2325 - val_loss: 0.2454\n",
      "Epoch 879/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2327 - val_loss: 0.2449\n",
      "Epoch 880/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2324 - val_loss: 0.2452\n",
      "Epoch 881/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2326 - val_loss: 0.2450\n",
      "Epoch 882/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2325 - val_loss: 0.2452\n",
      "Epoch 883/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2325 - val_loss: 0.2451\n",
      "Epoch 884/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2324 - val_loss: 0.2452\n",
      "Epoch 885/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2325 - val_loss: 0.2453\n",
      "Epoch 886/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2324 - val_loss: 0.2452\n",
      "Epoch 887/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2326 - val_loss: 0.2453\n",
      "Epoch 888/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2323 - val_loss: 0.2452\n",
      "Epoch 889/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2324 - val_loss: 0.2451\n",
      "Epoch 890/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2325 - val_loss: 0.2454\n",
      "Epoch 891/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2324 - val_loss: 0.2451\n",
      "Epoch 892/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2324 - val_loss: 0.2452\n",
      "Epoch 893/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2326 - val_loss: 0.2455\n",
      "Epoch 894/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2323 - val_loss: 0.2450\n",
      "Epoch 895/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2326 - val_loss: 0.2455\n",
      "Epoch 896/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2326 - val_loss: 0.2454\n",
      "Epoch 897/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2324 - val_loss: 0.2453\n",
      "Epoch 898/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2322 - val_loss: 0.2451\n",
      "Epoch 899/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2327 - val_loss: 0.2450\n",
      "Epoch 900/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2323 - val_loss: 0.2451\n",
      "Epoch 901/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2324 - val_loss: 0.2451\n",
      "Epoch 902/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2322 - val_loss: 0.2449\n",
      "Epoch 903/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2322 - val_loss: 0.2448\n",
      "Epoch 904/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2322 - val_loss: 0.2452\n",
      "Epoch 905/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2322 - val_loss: 0.2453\n",
      "Epoch 906/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2321 - val_loss: 0.2451\n",
      "Epoch 907/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2322 - val_loss: 0.2448\n",
      "Epoch 908/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2322 - val_loss: 0.2449\n",
      "Epoch 909/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2323 - val_loss: 0.2448\n",
      "Epoch 910/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2320 - val_loss: 0.2449\n",
      "Epoch 911/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2322 - val_loss: 0.2452\n",
      "Epoch 912/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2321 - val_loss: 0.2451\n",
      "Epoch 913/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2320 - val_loss: 0.2448\n",
      "Epoch 914/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2322 - val_loss: 0.2454\n",
      "Epoch 915/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2319 - val_loss: 0.2451\n",
      "Epoch 916/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2320 - val_loss: 0.2452\n",
      "Epoch 917/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2319 - val_loss: 0.2449\n",
      "Epoch 918/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2319 - val_loss: 0.2446\n",
      "Epoch 919/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2319 - val_loss: 0.2453\n",
      "Epoch 920/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2321 - val_loss: 0.2448\n",
      "Epoch 921/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2320 - val_loss: 0.2449\n",
      "Epoch 922/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2320 - val_loss: 0.2450\n",
      "Epoch 923/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2320 - val_loss: 0.2450\n",
      "Epoch 924/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2319 - val_loss: 0.2449\n",
      "Epoch 925/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2320 - val_loss: 0.2450\n",
      "Epoch 926/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2318 - val_loss: 0.2451\n",
      "Epoch 927/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2319 - val_loss: 0.2448\n",
      "Epoch 928/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2318 - val_loss: 0.2448\n",
      "Epoch 929/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2318 - val_loss: 0.2450\n",
      "Epoch 930/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2318 - val_loss: 0.2445\n",
      "Epoch 931/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2320 - val_loss: 0.2447\n",
      "Epoch 932/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2318 - val_loss: 0.2446\n",
      "Epoch 933/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2317 - val_loss: 0.2448\n",
      "Epoch 934/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2318 - val_loss: 0.2448\n",
      "Epoch 935/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2317 - val_loss: 0.2445\n",
      "Epoch 936/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2318 - val_loss: 0.2449\n",
      "Epoch 937/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2318 - val_loss: 0.2450\n",
      "Epoch 938/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2318 - val_loss: 0.2446\n",
      "Epoch 939/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2317 - val_loss: 0.2447\n",
      "Epoch 940/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.2452\n",
      "Epoch 941/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2317 - val_loss: 0.2444\n",
      "Epoch 942/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2319 - val_loss: 0.2452\n",
      "Epoch 943/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2317 - val_loss: 0.2445\n",
      "Epoch 944/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2315 - val_loss: 0.2449\n",
      "Epoch 945/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2315 - val_loss: 0.2445\n",
      "Epoch 946/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2315 - val_loss: 0.2449\n",
      "Epoch 947/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2319 - val_loss: 0.2447\n",
      "Epoch 948/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.2447\n",
      "Epoch 949/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.2451\n",
      "Epoch 950/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.2447\n",
      "Epoch 951/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2315 - val_loss: 0.2445\n",
      "Epoch 952/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.2454\n",
      "Epoch 953/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2315 - val_loss: 0.2447\n",
      "Epoch 954/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2315 - val_loss: 0.2447\n",
      "Epoch 955/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2313 - val_loss: 0.2446\n",
      "Epoch 956/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2315 - val_loss: 0.2446\n",
      "Epoch 957/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2315 - val_loss: 0.2447\n",
      "Epoch 958/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2317 - val_loss: 0.2446\n",
      "Epoch 959/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2317 - val_loss: 0.2446\n",
      "Epoch 960/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2314 - val_loss: 0.2447\n",
      "Epoch 961/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.2450\n",
      "Epoch 962/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2315 - val_loss: 0.2447\n",
      "Epoch 963/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2314 - val_loss: 0.2445\n",
      "Epoch 964/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2313 - val_loss: 0.2444\n",
      "Epoch 965/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2315 - val_loss: 0.2456\n",
      "Epoch 966/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2317 - val_loss: 0.2446\n",
      "Epoch 967/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2312 - val_loss: 0.2446\n",
      "Epoch 968/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2314 - val_loss: 0.2444\n",
      "Epoch 969/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2314 - val_loss: 0.2446\n",
      "Epoch 970/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2313 - val_loss: 0.2447\n",
      "Epoch 971/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2315 - val_loss: 0.2446\n",
      "Epoch 972/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2312 - val_loss: 0.2447\n",
      "Epoch 973/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2313 - val_loss: 0.2448\n",
      "Epoch 974/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2311 - val_loss: 0.2446\n",
      "Epoch 975/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2312 - val_loss: 0.2441\n",
      "Epoch 976/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2313 - val_loss: 0.2444\n",
      "Epoch 977/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2311 - val_loss: 0.2444\n",
      "Epoch 978/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2311 - val_loss: 0.2443\n",
      "Epoch 979/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2311 - val_loss: 0.2443\n",
      "Epoch 980/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2312 - val_loss: 0.2446\n",
      "Epoch 981/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2311 - val_loss: 0.2444\n",
      "Epoch 982/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2312 - val_loss: 0.2446\n",
      "Epoch 983/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2311 - val_loss: 0.2443\n",
      "Epoch 984/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2312 - val_loss: 0.2443\n",
      "Epoch 985/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2311 - val_loss: 0.2445\n",
      "Epoch 986/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2311 - val_loss: 0.2447\n",
      "Epoch 987/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2312 - val_loss: 0.2443\n",
      "Epoch 988/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2311 - val_loss: 0.2444\n",
      "Epoch 989/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2312 - val_loss: 0.2460\n",
      "Epoch 990/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2312 - val_loss: 0.2448\n",
      "Epoch 991/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2311 - val_loss: 0.2452\n",
      "Epoch 992/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2312 - val_loss: 0.2447\n",
      "Epoch 993/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2311 - val_loss: 0.2445\n",
      "Epoch 994/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2311 - val_loss: 0.2445\n",
      "Epoch 995/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2311 - val_loss: 0.2444\n",
      "Epoch 996/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2310 - val_loss: 0.2441\n",
      "Epoch 997/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2310 - val_loss: 0.2447\n",
      "Epoch 998/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2310 - val_loss: 0.2441\n",
      "Epoch 999/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2308 - val_loss: 0.2447\n",
      "Epoch 1000/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2309 - val_loss: 0.2443\n",
      "Epoch 1001/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2309 - val_loss: 0.2444\n",
      "Epoch 1002/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2308 - val_loss: 0.2443\n",
      "Epoch 1003/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2308 - val_loss: 0.2441\n",
      "Epoch 1004/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2309 - val_loss: 0.2446\n",
      "Epoch 1005/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2308 - val_loss: 0.2443\n",
      "Epoch 1006/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2308 - val_loss: 0.2443\n",
      "Epoch 1007/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2309 - val_loss: 0.2443\n",
      "Epoch 1008/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2309 - val_loss: 0.2442\n",
      "Epoch 1009/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2309 - val_loss: 0.2442\n",
      "Epoch 1010/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2308 - val_loss: 0.2443\n",
      "Epoch 1011/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2310 - val_loss: 0.2449\n",
      "Epoch 1012/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2310 - val_loss: 0.2440\n",
      "Epoch 1013/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2309 - val_loss: 0.2442\n",
      "Epoch 1014/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2309 - val_loss: 0.2444\n",
      "Epoch 1015/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2308 - val_loss: 0.2441\n",
      "Epoch 1016/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2309 - val_loss: 0.2441\n",
      "Epoch 1017/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2306 - val_loss: 0.2443\n",
      "Epoch 1018/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2310 - val_loss: 0.2439\n",
      "Epoch 1019/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2307 - val_loss: 0.2446\n",
      "Epoch 1020/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2307 - val_loss: 0.2444\n",
      "Epoch 1021/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2308 - val_loss: 0.2443\n",
      "Epoch 1022/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2306 - val_loss: 0.2438\n",
      "Epoch 1023/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2307 - val_loss: 0.2440\n",
      "Epoch 1024/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2307 - val_loss: 0.2442\n",
      "Epoch 1025/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2307 - val_loss: 0.2443\n",
      "Epoch 1026/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2307 - val_loss: 0.2440\n",
      "Epoch 1027/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2308 - val_loss: 0.2442\n",
      "Epoch 1028/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2307 - val_loss: 0.2440\n",
      "Epoch 1029/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2307 - val_loss: 0.2445\n",
      "Epoch 1030/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2306 - val_loss: 0.2438\n",
      "Epoch 1031/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2305 - val_loss: 0.2440\n",
      "Epoch 1032/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2306 - val_loss: 0.2439\n",
      "Epoch 1033/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2305 - val_loss: 0.2441\n",
      "Epoch 1034/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2306 - val_loss: 0.2440\n",
      "Epoch 1035/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2308 - val_loss: 0.2441\n",
      "Epoch 1036/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2307 - val_loss: 0.2441\n",
      "Epoch 1037/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2304 - val_loss: 0.2440\n",
      "Epoch 1038/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2307 - val_loss: 0.2441\n",
      "Epoch 1039/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2305 - val_loss: 0.2445\n",
      "Epoch 1040/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2306 - val_loss: 0.2443\n",
      "Epoch 1041/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2305 - val_loss: 0.2443\n",
      "Epoch 1042/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2305 - val_loss: 0.2439\n",
      "Epoch 1043/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2305 - val_loss: 0.2441\n",
      "Epoch 1044/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2305 - val_loss: 0.2443\n",
      "Epoch 1045/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2304 - val_loss: 0.2439\n",
      "Epoch 1046/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2303 - val_loss: 0.2442\n",
      "Epoch 1047/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2305 - val_loss: 0.2437\n",
      "Epoch 1048/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2304 - val_loss: 0.2441\n",
      "Epoch 1049/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2304 - val_loss: 0.2443\n",
      "Epoch 1050/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2306 - val_loss: 0.2439\n",
      "Epoch 1051/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2305 - val_loss: 0.2442\n",
      "Epoch 1052/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2304 - val_loss: 0.2438\n",
      "Epoch 1053/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2304 - val_loss: 0.2437\n",
      "Epoch 1054/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2304 - val_loss: 0.2443\n",
      "Epoch 1055/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2304 - val_loss: 0.2438\n",
      "Epoch 1056/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2305 - val_loss: 0.2436\n",
      "Epoch 1057/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2303 - val_loss: 0.2441\n",
      "Epoch 1058/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2303 - val_loss: 0.2439\n",
      "Epoch 1059/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2303 - val_loss: 0.2438\n",
      "Epoch 1060/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2304 - val_loss: 0.2442\n",
      "Epoch 1061/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2304 - val_loss: 0.2445\n",
      "Epoch 1062/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2304 - val_loss: 0.2438\n",
      "Epoch 1063/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2303 - val_loss: 0.2440\n",
      "Epoch 1064/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2302 - val_loss: 0.2439\n",
      "Epoch 1065/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2302 - val_loss: 0.2441\n",
      "Epoch 1066/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2303 - val_loss: 0.2438\n",
      "Epoch 1067/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2304 - val_loss: 0.2436\n",
      "Epoch 1068/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2302 - val_loss: 0.2441\n",
      "Epoch 1069/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2305 - val_loss: 0.2437\n",
      "Epoch 1070/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2301 - val_loss: 0.2441\n",
      "Epoch 1071/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2303 - val_loss: 0.2439\n",
      "Epoch 1072/2000\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.2302 - val_loss: 0.2438\n",
      "Epoch 1073/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2302 - val_loss: 0.2438\n",
      "Epoch 1074/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2301 - val_loss: 0.2439\n",
      "Epoch 1075/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2301 - val_loss: 0.2446\n",
      "Epoch 1076/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2302 - val_loss: 0.2435\n",
      "Epoch 1077/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2300 - val_loss: 0.2438\n",
      "Epoch 1078/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2300 - val_loss: 0.2439\n",
      "Epoch 1079/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2301 - val_loss: 0.2438\n",
      "Epoch 1080/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2300 - val_loss: 0.2438\n",
      "Epoch 1081/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2301 - val_loss: 0.2436\n",
      "Epoch 1082/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2300 - val_loss: 0.2440\n",
      "Epoch 1083/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2300 - val_loss: 0.2439\n",
      "Epoch 1084/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2299 - val_loss: 0.2435\n",
      "Epoch 1085/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2302 - val_loss: 0.2437\n",
      "Epoch 1086/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2301 - val_loss: 0.2440\n",
      "Epoch 1087/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2300 - val_loss: 0.2433\n",
      "Epoch 1088/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2300 - val_loss: 0.2442\n",
      "Epoch 1089/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2301 - val_loss: 0.2442\n",
      "Epoch 1090/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2300 - val_loss: 0.2436\n",
      "Epoch 1091/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2300 - val_loss: 0.2436\n",
      "Epoch 1092/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2300 - val_loss: 0.2436\n",
      "Epoch 1093/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2300 - val_loss: 0.2441\n",
      "Epoch 1094/2000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.2299 - val_loss: 0.2437\n",
      "Epoch 1095/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2301 - val_loss: 0.2438\n",
      "Epoch 1096/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2299 - val_loss: 0.2437\n",
      "Epoch 1097/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2299 - val_loss: 0.2436\n",
      "Epoch 1098/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2299 - val_loss: 0.2444\n",
      "Epoch 1099/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2300 - val_loss: 0.2439\n",
      "Epoch 1100/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2298 - val_loss: 0.2438\n",
      "Epoch 1101/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2300 - val_loss: 0.2435\n",
      "Epoch 1102/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2299 - val_loss: 0.2436\n",
      "Epoch 1103/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2299 - val_loss: 0.2435\n",
      "Epoch 1104/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2299 - val_loss: 0.2434\n",
      "Epoch 1105/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2298 - val_loss: 0.2440\n",
      "Epoch 1106/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2298 - val_loss: 0.2436\n",
      "Epoch 1107/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2299 - val_loss: 0.2440\n",
      "Epoch 1108/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2299 - val_loss: 0.2437\n",
      "Epoch 1109/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2298 - val_loss: 0.2433\n",
      "Epoch 1110/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2298 - val_loss: 0.2435\n",
      "Epoch 1111/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2299 - val_loss: 0.2437\n",
      "Epoch 1112/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2299 - val_loss: 0.2439\n",
      "Epoch 1113/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2298 - val_loss: 0.2436\n",
      "Epoch 1114/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2297 - val_loss: 0.2441\n",
      "Epoch 1115/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2297 - val_loss: 0.2433\n",
      "Epoch 1116/2000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2296 - val_loss: 0.2436\n",
      "Epoch 1117/2000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2297 - val_loss: 0.2435\n",
      "Epoch 1118/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2300 - val_loss: 0.2434\n",
      "Epoch 1119/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2298 - val_loss: 0.2434\n",
      "Epoch 1120/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2297 - val_loss: 0.2435\n",
      "Epoch 1121/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2298 - val_loss: 0.2434\n",
      "Epoch 1122/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2298 - val_loss: 0.2437\n",
      "Epoch 1123/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2297 - val_loss: 0.2439\n",
      "Epoch 1124/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2298 - val_loss: 0.2435\n",
      "Epoch 1125/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2295 - val_loss: 0.2437\n",
      "Epoch 1126/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2298 - val_loss: 0.2433\n",
      "Epoch 1127/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2298 - val_loss: 0.2435\n",
      "Epoch 1128/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2297 - val_loss: 0.2435\n",
      "Epoch 1129/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2297 - val_loss: 0.2440\n",
      "Epoch 1130/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2297 - val_loss: 0.2438\n",
      "Epoch 1131/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2295 - val_loss: 0.2438\n",
      "Epoch 1132/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2295 - val_loss: 0.2437\n",
      "Epoch 1133/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2296 - val_loss: 0.2436\n",
      "Epoch 1134/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2296 - val_loss: 0.2434\n",
      "Epoch 1135/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2295 - val_loss: 0.2438\n",
      "Epoch 1136/2000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.2296 - val_loss: 0.2434\n",
      "Epoch 1137/2000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.2295 - val_loss: 0.2435\n",
      "Epoch 1137: early stopping\n",
      "358.33315992355347\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "history2 = model2.fit(X_train,y_train,epochs=2000,callbacks=callback,batch_size=2500,validation_split=0.2)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12b9a9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 1s 945us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9660400125063358"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2= model2.predict(X_test)\n",
    "r2_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "633dbd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13718f439a0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802cd94c",
   "metadata": {},
   "source": [
    "#### Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3cfde6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Dense(416,activation='tanh',input_dim=X_train.shape[1]))\n",
    "model3.add(Dense(416,activation='sigmoid'))\n",
    "model3.add(Dense(32,activation='relu'))\n",
    "model3.add(Dense(32,activation='relu'))\n",
    "model3.add(Dense(32,activation='relu'))\n",
    "\n",
    "\n",
    "model3.add(Dense(1,activation='linear'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f62e22cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 192)               2304      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 416)               80288     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 448)               186816    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                14368     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 294,369\n",
      "Trainable params: 294,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38781a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05f39f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='mean_squared_error',optimizer= opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd8796b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 2s 82ms/step - loss: 27.5374 - val_loss: 24.6827\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 22.5423 - val_loss: 19.4636\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 17.3011 - val_loss: 14.5241\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 12.7777 - val_loss: 10.5532\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 9.1382 - val_loss: 7.3688\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 6.2791 - val_loss: 4.9804\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 4.2348 - val_loss: 3.4126\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 2.9690 - val_loss: 2.5346\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 2.2979 - val_loss: 2.1066\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.9783 - val_loss: 1.9009\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 1.8112 - val_loss: 1.7730\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 1.6933 - val_loss: 1.6624\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 1.5874 - val_loss: 1.5605\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 1.4906 - val_loss: 1.4684\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 1.4047 - val_loss: 1.3865\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 1.3279 - val_loss: 1.3142\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 1.2604 - val_loss: 1.2505\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 1.2005 - val_loss: 1.1943\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 1.1472 - val_loss: 1.1439\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 1.0995 - val_loss: 1.0985\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.0558 - val_loss: 1.0561\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.0147 - val_loss: 1.0163\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.9762 - val_loss: 0.9789\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.9401 - val_loss: 0.9437\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.9064 - val_loss: 0.9121\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.8762 - val_loss: 0.8833\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.8487 - val_loss: 0.8571\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.8238 - val_loss: 0.8334\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.8010 - val_loss: 0.8115\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.7799 - val_loss: 0.7915\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.7607 - val_loss: 0.7728\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.7426 - val_loss: 0.7556\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7260 - val_loss: 0.7395\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.7104 - val_loss: 0.7245\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.6960 - val_loss: 0.7105\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.6823 - val_loss: 0.6971\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6694 - val_loss: 0.6849\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.6577 - val_loss: 0.6731\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.6465 - val_loss: 0.6622\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.6361 - val_loss: 0.6520\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6264 - val_loss: 0.6423\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.6172 - val_loss: 0.6333\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.6085 - val_loss: 0.6247\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.6003 - val_loss: 0.6166\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.5926 - val_loss: 0.6088\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5853 - val_loss: 0.6014\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.5783 - val_loss: 0.5944\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.5718 - val_loss: 0.5876\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.5654 - val_loss: 0.5813\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.5594 - val_loss: 0.5754\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.5536 - val_loss: 0.5692\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.5480 - val_loss: 0.5638\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.5427 - val_loss: 0.5582\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5377 - val_loss: 0.5529\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.5324 - val_loss: 0.5478\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.5278 - val_loss: 0.5428\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.5230 - val_loss: 0.5380\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.5188 - val_loss: 0.5334\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.5143 - val_loss: 0.5289\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.5102 - val_loss: 0.5250\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5060 - val_loss: 0.5204\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5021 - val_loss: 0.5163\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.4983 - val_loss: 0.5125\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.4946 - val_loss: 0.5086\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.4911 - val_loss: 0.5047\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.4874 - val_loss: 0.5011\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.4840 - val_loss: 0.4974\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.4807 - val_loss: 0.4939\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.4775 - val_loss: 0.4904\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.4743 - val_loss: 0.4871\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.4712 - val_loss: 0.4838\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.4682 - val_loss: 0.4806\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.4651 - val_loss: 0.4775\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.4623 - val_loss: 0.4751\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.4595 - val_loss: 0.4713\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.4566 - val_loss: 0.4682\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.4538 - val_loss: 0.4653\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.4511 - val_loss: 0.4625\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.4484 - val_loss: 0.4599\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.4458 - val_loss: 0.4570\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.4433 - val_loss: 0.4542\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4408 - val_loss: 0.4515\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.4383 - val_loss: 0.4495\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.4358 - val_loss: 0.4463\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.4335 - val_loss: 0.4439\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4311 - val_loss: 0.4414\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.4289 - val_loss: 0.4392\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.4266 - val_loss: 0.4368\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.4245 - val_loss: 0.4344\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.4220 - val_loss: 0.4318\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.4199 - val_loss: 0.4295\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4175 - val_loss: 0.4270\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.4151 - val_loss: 0.4246\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.4126 - val_loss: 0.4217\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.4099 - val_loss: 0.4189\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.4072 - val_loss: 0.4160\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.4044 - val_loss: 0.4132\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.4015 - val_loss: 0.4100\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.3986 - val_loss: 0.4069\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.3956 - val_loss: 0.4043\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.3926 - val_loss: 0.4009\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.3895 - val_loss: 0.3970\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.3858 - val_loss: 0.3937\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.3820 - val_loss: 0.3895\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.3780 - val_loss: 0.3852\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.3739 - val_loss: 0.3811\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.3695 - val_loss: 0.3770\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.3654 - val_loss: 0.3724\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.3612 - val_loss: 0.3680\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.3571 - val_loss: 0.3642\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.3532 - val_loss: 0.3606\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.3492 - val_loss: 0.3561\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.3454 - val_loss: 0.3524\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.3419 - val_loss: 0.3484\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.3387 - val_loss: 0.3452\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.3351 - val_loss: 0.3416\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.3320 - val_loss: 0.3382\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.3286 - val_loss: 0.3349\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.3255 - val_loss: 0.3317\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.3225 - val_loss: 0.3291\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.3198 - val_loss: 0.3261\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.3172 - val_loss: 0.3232\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.3146 - val_loss: 0.3205\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.3121 - val_loss: 0.3181\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.3099 - val_loss: 0.3159\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.3073 - val_loss: 0.3127\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.3050 - val_loss: 0.3103\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.3029 - val_loss: 0.3091\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.3011 - val_loss: 0.3059\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.2989 - val_loss: 0.3038\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.2966 - val_loss: 0.3016\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2948 - val_loss: 0.3000\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.2931 - val_loss: 0.2979\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2913 - val_loss: 0.2962\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2897 - val_loss: 0.2946\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2882 - val_loss: 0.2929\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2866 - val_loss: 0.2907\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2852 - val_loss: 0.2896\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2837 - val_loss: 0.2884\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.2829 - val_loss: 0.2878\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2814 - val_loss: 0.2855\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2801 - val_loss: 0.2842\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.2790 - val_loss: 0.2833\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2781 - val_loss: 0.2823\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2770 - val_loss: 0.2812\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2761 - val_loss: 0.2804\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2754 - val_loss: 0.2807\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.2752 - val_loss: 0.2785\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2741 - val_loss: 0.2779\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2730 - val_loss: 0.2771\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.2722 - val_loss: 0.2769\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.2720 - val_loss: 0.2760\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.2713 - val_loss: 0.2755\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2705 - val_loss: 0.2747\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.2699 - val_loss: 0.2739\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.2693 - val_loss: 0.2737\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.2685 - val_loss: 0.2726\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.2681 - val_loss: 0.2724\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.2675 - val_loss: 0.2717\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.2672 - val_loss: 0.2716\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.2667 - val_loss: 0.2712\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2663 - val_loss: 0.2711\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2658 - val_loss: 0.2698\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2654 - val_loss: 0.2697\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2651 - val_loss: 0.2700\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2647 - val_loss: 0.2686\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2645 - val_loss: 0.2681\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2642 - val_loss: 0.2678\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2637 - val_loss: 0.2694\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2635 - val_loss: 0.2678\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2629 - val_loss: 0.2670\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.2626 - val_loss: 0.2669\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2623 - val_loss: 0.2670\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2622 - val_loss: 0.2659\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2619 - val_loss: 0.2658\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.2616 - val_loss: 0.2656\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.2619 - val_loss: 0.2666\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.2612 - val_loss: 0.2655\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2609 - val_loss: 0.2650\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2608 - val_loss: 0.2654\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2602 - val_loss: 0.2643\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2604 - val_loss: 0.2636\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2602 - val_loss: 0.2640\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2599 - val_loss: 0.2638\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2596 - val_loss: 0.2643\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2593 - val_loss: 0.2633\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2588 - val_loss: 0.2626\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2586 - val_loss: 0.2631\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2586 - val_loss: 0.2626\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2584 - val_loss: 0.2634\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2585 - val_loss: 0.2629\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2579 - val_loss: 0.2624\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2580 - val_loss: 0.2616\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2577 - val_loss: 0.2621\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2576 - val_loss: 0.2621\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2574 - val_loss: 0.2618\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2571 - val_loss: 0.2614\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2571 - val_loss: 0.2616\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2569 - val_loss: 0.2608\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2569 - val_loss: 0.2615\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2567 - val_loss: 0.2609\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2567 - val_loss: 0.2603\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2564 - val_loss: 0.2606\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2561 - val_loss: 0.2604\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2561 - val_loss: 0.2607\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2557 - val_loss: 0.2599\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2559 - val_loss: 0.2599\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2556 - val_loss: 0.2598\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2554 - val_loss: 0.2599\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2552 - val_loss: 0.2598\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2552 - val_loss: 0.2603\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2553 - val_loss: 0.2599\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2550 - val_loss: 0.2591\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2548 - val_loss: 0.2597\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2548 - val_loss: 0.2596\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2546 - val_loss: 0.2589\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2544 - val_loss: 0.2593\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2544 - val_loss: 0.2586\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2548 - val_loss: 0.2602\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2550 - val_loss: 0.2588\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2545 - val_loss: 0.2590\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2541 - val_loss: 0.2600\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2541 - val_loss: 0.2583\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2536 - val_loss: 0.2585\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2541 - val_loss: 0.2583\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2536 - val_loss: 0.2589\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2536 - val_loss: 0.2590\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2534 - val_loss: 0.2580\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2533 - val_loss: 0.2588\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2535 - val_loss: 0.2581\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2530 - val_loss: 0.2582\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2533 - val_loss: 0.2578\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2529 - val_loss: 0.2581\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2528 - val_loss: 0.2578\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2527 - val_loss: 0.2573\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2530 - val_loss: 0.2571\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2525 - val_loss: 0.2572\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2523 - val_loss: 0.2572\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2529 - val_loss: 0.2572\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2524 - val_loss: 0.2572\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2520 - val_loss: 0.2572\n",
      "Epoch 242/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2518 - val_loss: 0.2567\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2519 - val_loss: 0.2577\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2520 - val_loss: 0.2571\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2519 - val_loss: 0.2567\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.2523 - val_loss: 0.2568\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2522 - val_loss: 0.2568\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.2514 - val_loss: 0.2576\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2519 - val_loss: 0.2565\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2514 - val_loss: 0.2566\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2511 - val_loss: 0.2562\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2514 - val_loss: 0.2567\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2511 - val_loss: 0.2570\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2513 - val_loss: 0.2565\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2511 - val_loss: 0.2568\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2509 - val_loss: 0.2576\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2518 - val_loss: 0.2562\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2507 - val_loss: 0.2562\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2508 - val_loss: 0.2564\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2507 - val_loss: 0.2566\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2506 - val_loss: 0.2559\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2506 - val_loss: 0.2565\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2510 - val_loss: 0.2563\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2507 - val_loss: 0.2557\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2505 - val_loss: 0.2562\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2503 - val_loss: 0.2557\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2502 - val_loss: 0.2556\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2501 - val_loss: 0.2555\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2499 - val_loss: 0.2557\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2503 - val_loss: 0.2551\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2501 - val_loss: 0.2552\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2496 - val_loss: 0.2557\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2497 - val_loss: 0.2564\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2497 - val_loss: 0.2560\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2498 - val_loss: 0.2551\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2493 - val_loss: 0.2556\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2494 - val_loss: 0.2550\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2491 - val_loss: 0.2552\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2492 - val_loss: 0.2550\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2492 - val_loss: 0.2551\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2493 - val_loss: 0.2554\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2492 - val_loss: 0.2548\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2492 - val_loss: 0.2555\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2489 - val_loss: 0.2548\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.2489 - val_loss: 0.2549\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2490 - val_loss: 0.2550\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2487 - val_loss: 0.2567\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2494 - val_loss: 0.2552\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2487 - val_loss: 0.2552\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2487 - val_loss: 0.2541\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2485 - val_loss: 0.2554\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2484 - val_loss: 0.2542\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2486 - val_loss: 0.2550\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2484 - val_loss: 0.2544\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2484 - val_loss: 0.2545\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2482 - val_loss: 0.2547\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2484 - val_loss: 0.2548\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2482 - val_loss: 0.2540\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2482 - val_loss: 0.2539\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2479 - val_loss: 0.2538\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2481 - val_loss: 0.2539\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2476 - val_loss: 0.2539\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2482 - val_loss: 0.2541\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2481 - val_loss: 0.2542\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2477 - val_loss: 0.2558\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2478 - val_loss: 0.2544\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2474 - val_loss: 0.2558\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2482 - val_loss: 0.2539\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2474 - val_loss: 0.2537\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2475 - val_loss: 0.2537\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2475 - val_loss: 0.2535\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2476 - val_loss: 0.2551\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2475 - val_loss: 0.2543\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2472 - val_loss: 0.2540\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2470 - val_loss: 0.2537\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2473 - val_loss: 0.2535\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2467 - val_loss: 0.2531\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2468 - val_loss: 0.2536\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2467 - val_loss: 0.2536\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2469 - val_loss: 0.2540\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2467 - val_loss: 0.2534\n",
      "Epoch 322/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2464 - val_loss: 0.2531\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2466 - val_loss: 0.2530\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2464 - val_loss: 0.2537\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2465 - val_loss: 0.2540\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2465 - val_loss: 0.2531\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2465 - val_loss: 0.2537\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2464 - val_loss: 0.2542\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2465 - val_loss: 0.2535\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2460 - val_loss: 0.2530\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2460 - val_loss: 0.2531\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2461 - val_loss: 0.2539\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2461 - val_loss: 0.2535\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2460 - val_loss: 0.2530\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2462 - val_loss: 0.2533\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2458 - val_loss: 0.2527\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2457 - val_loss: 0.2536\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2460 - val_loss: 0.2526\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2457 - val_loss: 0.2542\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2459 - val_loss: 0.2532\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2457 - val_loss: 0.2526\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2453 - val_loss: 0.2529\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2456 - val_loss: 0.2527\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2455 - val_loss: 0.2533\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2453 - val_loss: 0.2535\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2454 - val_loss: 0.2521\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2453 - val_loss: 0.2521\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2454 - val_loss: 0.2519\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2455 - val_loss: 0.2529\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2456 - val_loss: 0.2532\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2456 - val_loss: 0.2525\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2452 - val_loss: 0.2518\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2448 - val_loss: 0.2521\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2447 - val_loss: 0.2521\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2447 - val_loss: 0.2520\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2448 - val_loss: 0.2522\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2453 - val_loss: 0.2532\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2447 - val_loss: 0.2516\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2445 - val_loss: 0.2523\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2447 - val_loss: 0.2527\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2446 - val_loss: 0.2529\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2445 - val_loss: 0.2519\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2443 - val_loss: 0.2514\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2444 - val_loss: 0.2528\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2449 - val_loss: 0.2533\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2443 - val_loss: 0.2511\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2439 - val_loss: 0.2511\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2439 - val_loss: 0.2521\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2443 - val_loss: 0.2524\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2441 - val_loss: 0.2512\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2441 - val_loss: 0.2512\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2444 - val_loss: 0.2512\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2444 - val_loss: 0.2515\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2442 - val_loss: 0.2530\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2441 - val_loss: 0.2509\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2438 - val_loss: 0.2511\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2437 - val_loss: 0.2508\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2437 - val_loss: 0.2506\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2434 - val_loss: 0.2506\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2433 - val_loss: 0.2516\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2436 - val_loss: 0.2504\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2437 - val_loss: 0.2504\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2434 - val_loss: 0.2512\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2433 - val_loss: 0.2526\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2437 - val_loss: 0.2509\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2434 - val_loss: 0.2506\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2431 - val_loss: 0.2503\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2433 - val_loss: 0.2508\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2435 - val_loss: 0.2506\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2431 - val_loss: 0.2504\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2431 - val_loss: 0.2504\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2429 - val_loss: 0.2499\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2428 - val_loss: 0.2503\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2426 - val_loss: 0.2502\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2429 - val_loss: 0.2505\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2426 - val_loss: 0.2511\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2431 - val_loss: 0.2505\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.2428 - val_loss: 0.2511\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2426 - val_loss: 0.2504\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2427 - val_loss: 0.2510\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2429 - val_loss: 0.2503\n",
      "Epoch 402/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2426 - val_loss: 0.2503\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.2423 - val_loss: 0.2508\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2424 - val_loss: 0.2508\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2425 - val_loss: 0.2499\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.2427 - val_loss: 0.2508\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.2423 - val_loss: 0.2501\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2430 - val_loss: 0.2504\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2426 - val_loss: 0.2504\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.2424 - val_loss: 0.2511\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.2423 - val_loss: 0.2494\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.2424 - val_loss: 0.2499\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.2421 - val_loss: 0.2494\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.2419 - val_loss: 0.2504\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.2422 - val_loss: 0.2495\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.2419 - val_loss: 0.2501\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.2418 - val_loss: 0.2493\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.2417 - val_loss: 0.2497\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.2418 - val_loss: 0.2497\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.2417 - val_loss: 0.2516\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.2422 - val_loss: 0.2515\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.2420 - val_loss: 0.2497\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.2417 - val_loss: 0.2499\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.2418 - val_loss: 0.2500\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.2418 - val_loss: 0.2496\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.2417 - val_loss: 0.2493\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.2414 - val_loss: 0.2492\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.2411 - val_loss: 0.2494\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.2410 - val_loss: 0.2502\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.2415 - val_loss: 0.2493\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.2411 - val_loss: 0.2492\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.2412 - val_loss: 0.2498\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.2411 - val_loss: 0.2491\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.2411 - val_loss: 0.2494\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.2416 - val_loss: 0.2492\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.2415 - val_loss: 0.2485\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.2412 - val_loss: 0.2487\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.2411 - val_loss: 0.2493\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.2416 - val_loss: 0.2489\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.2415 - val_loss: 0.2492\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.2409 - val_loss: 0.2491\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.2410 - val_loss: 0.2493\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.2407 - val_loss: 0.2485\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.2407 - val_loss: 0.2508\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.2416 - val_loss: 0.2488\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.2411 - val_loss: 0.2488\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2407 - val_loss: 0.2489\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.2406 - val_loss: 0.2488\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2404 - val_loss: 0.2485\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2407 - val_loss: 0.2487\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.2404 - val_loss: 0.2484\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.2408 - val_loss: 0.2486\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.2406 - val_loss: 0.2492\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2402 - val_loss: 0.2487\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.2403 - val_loss: 0.2497\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.2405 - val_loss: 0.2499\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2402 - val_loss: 0.2493\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2403 - val_loss: 0.2492\n",
      "Epoch 459/500\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.2404 - val_loss: 0.2486\n",
      "Epoch 460/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.2400 - val_loss: 0.2484\n",
      "Epoch 461/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.2399 - val_loss: 0.2493\n",
      "Epoch 462/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2402 - val_loss: 0.2482\n",
      "Epoch 463/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.2400 - val_loss: 0.2485\n",
      "Epoch 464/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2403 - val_loss: 0.2478\n",
      "Epoch 465/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2398 - val_loss: 0.2486\n",
      "Epoch 466/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.2398 - val_loss: 0.2493\n",
      "Epoch 467/500\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.2401 - val_loss: 0.2488\n",
      "Epoch 468/500\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.2398 - val_loss: 0.2481\n",
      "Epoch 469/500\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.2398 - val_loss: 0.2479\n",
      "Epoch 470/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.2397 - val_loss: 0.2485\n",
      "Epoch 471/500\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.2402 - val_loss: 0.2481\n",
      "Epoch 472/500\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.2405 - val_loss: 0.2487\n",
      "Epoch 473/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.2399 - val_loss: 0.2482\n",
      "Epoch 474/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.2405 - val_loss: 0.2476\n",
      "Epoch 475/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.2398 - val_loss: 0.2475\n",
      "Epoch 476/500\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.2395 - val_loss: 0.2477\n",
      "Epoch 477/500\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.2394 - val_loss: 0.2479\n",
      "Epoch 478/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.2395 - val_loss: 0.2472\n",
      "Epoch 479/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.2392 - val_loss: 0.2471\n",
      "Epoch 480/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.2396 - val_loss: 0.2473\n",
      "Epoch 481/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.2397 - val_loss: 0.2477\n",
      "Epoch 482/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 84ms/step - loss: 0.2394 - val_loss: 0.2479\n",
      "Epoch 483/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.2392 - val_loss: 0.2478\n",
      "Epoch 484/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.2391 - val_loss: 0.2471\n",
      "Epoch 485/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.2391 - val_loss: 0.2478\n",
      "Epoch 486/500\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.2391 - val_loss: 0.2483\n",
      "Epoch 487/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2395 - val_loss: 0.2478\n",
      "Epoch 488/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2388 - val_loss: 0.2468\n",
      "Epoch 489/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2390 - val_loss: 0.2474\n",
      "Epoch 490/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2390 - val_loss: 0.2477\n",
      "Epoch 491/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2394 - val_loss: 0.2470\n",
      "Epoch 492/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2394 - val_loss: 0.2474\n",
      "Epoch 493/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2392 - val_loss: 0.2471\n",
      "Epoch 494/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.2391 - val_loss: 0.2479\n",
      "Epoch 495/500\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 0.2391 - val_loss: 0.2465\n",
      "Epoch 496/500\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 0.2390 - val_loss: 0.2474\n",
      "Epoch 497/500\n",
      "14/14 [==============================] - 1s 71ms/step - loss: 0.2390 - val_loss: 0.2474\n",
      "Epoch 498/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.2388 - val_loss: 0.2472\n",
      "Epoch 499/500\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.2392 - val_loss: 0.2468\n",
      "Epoch 500/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.2390 - val_loss: 0.2475\n",
      "579.784553527832\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "history3 = model3.fit(X_train,y_train,epochs=500,callbacks=callback,batch_size=6000,validation_split=0.2)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e07537f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9618875409733068"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3= model.predict(X_test)\n",
    "r2_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7b63c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1371b4a6e60>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aefec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
